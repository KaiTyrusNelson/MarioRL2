{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOU MUST RUN THIS IN PYTHON 3.8.1\n",
    "!pip install gym==0.21.0\n",
    "!pip install -qq gym-super-mario-bros\n",
    "!pip -qq install stable-baselines3==1.6.0\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d0b625-45ea-4efb-a49d-baef9fe70e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networks\n",
    "from env import train\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008027fc-aa83-4088-bc7a-cb6a9048c59e",
   "metadata": {},
   "source": [
    "### Training:\n",
    "\n",
    "Training of models can be performed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deb8319-2b06-46f1-bd3c-e1342a9b5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 198.8600006610155 average time: 114.85 best_reward: 421.4000016450882\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 191.10500072948633 average time: 112.0 best_reward: 421.300002142787\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 225.9850007493049 average time: 132.0 best_reward: 492.60000213980675\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 218.57000064104795 average time: 113.2 best_reward: 448.1000020876527\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 298.76000080518423 average time: 155.5 best_reward: 596.5000034943223\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 231.70500081516803 average time: 169.2 best_reward: 492.3000031262636\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 283.5850009869784 average time: 142.7 best_reward: 728.6000030115247\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 80000 / 500000\n",
      "average reward: 355.7500010214746 average time: 183.9 best_reward: 984.9000034406781\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 295.7700010530651 average time: 311.2 best_reward: 594.7000013664365\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 221.02000058926643 average time: 104.4 best_reward: 523.3000005930662\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 283.34500107243656 average time: 143.35 best_reward: 728.5000028982759\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 404.22500176765027 average time: 184.25 best_reward: 730.0000026002526\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 327.6800012480468 average time: 201.0 best_reward: 813.700003311038\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 274.3300012178719 average time: 128.65 best_reward: 447.5000020265579\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 279.3850011780858 average time: 128.35 best_reward: 728.0000034123659\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 309.20500142276285 average time: 136.4 best_reward: 576.2000024393201\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 370.3750016152859 average time: 159.1 best_reward: 729.8000039830804\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 433.3150016952306 average time: 189.8 best_reward: 813.700000859797\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 382.3100017402321 average time: 154.45 best_reward: 577.0000022128224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 429.9250018358231 average time: 194.8 best_reward: 814.0000032931566\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 210000 / 500000\n",
      "average reward: 459.04000177942214 average time: 200.35 best_reward: 986.800004683435\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 424.82000177390876 average time: 177.0 best_reward: 729.0000036805868\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 339.38500126600263 average time: 174.9 best_reward: 726.6000026538968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 450.85500183068217 average time: 195.0 best_reward: 730.3000023365021\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 305.75000114925206 average time: 175.05 best_reward: 730.0000028535724\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 380.61000158935786 average time: 248.0 best_reward: 730.0000025257468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 415.74000197276473 average time: 184.35 best_reward: 722.2000040411949\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 391.21000180095433 average time: 195.1 best_reward: 528.4000018313527\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 409.5150017697364 average time: 175.7 best_reward: 814.6000025346875\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 519.7150021038949 average time: 247.45 best_reward: 729.7000021636486\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 581.4500027693808 average time: 247.3 best_reward: 815.2000033780932\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 393.6150016374886 average time: 156.35 best_reward: 731.8000030815601\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 437.70500192902983 average time: 181.2 best_reward: 816.3000039607286\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 524.4050021879375 average time: 230.8 best_reward: 986.4000032320619\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 269.2350011508912 average time: 317.8 best_reward: 525.7000022530556\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 431.6200017519295 average time: 211.0 best_reward: 981.8000031635165\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 370000 / 500000\n",
      "average reward: 529.2400022301823 average time: 289.8 best_reward: 985.9000048264861\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 465.76500178948044 average time: 254.8 best_reward: 987.6000041291118\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 437.58000177741053 average time: 242.05 best_reward: 983.400005504489\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 258.545000968501 average time: 318.4 best_reward: 594.0000024735928\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 364.5800014317036 average time: 299.8 best_reward: 983.3000006973743\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 375.0600014850497 average time: 190.85 best_reward: 986.0000026673079\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 346.8350014910102 average time: 165.1 best_reward: 727.9000037759542\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 382.7850016012788 average time: 212.4 best_reward: 981.9000024348497\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 444.0250021275133 average time: 262.45 best_reward: 866.8000039532781\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 420.45000174678864 average time: 264.6 best_reward: 813.9000031799078\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 446.9650018341839 average time: 271.8 best_reward: 986.60000243783\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 384.00000154264274 average time: 265.75 best_reward: 814.2000033259392\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 392.32000191845 average time: 161.1 best_reward: 986.1000062972307\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 315.3350013256073 average time: 198.05 best_reward: 727.7000033706427\n"
     ]
    }
   ],
   "source": [
    "train('./None', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9cdd77-05aa-477f-954c-03136e2ef5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 253.91500056572258 average time: 146.2 best_reward: 491.8000001832843\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 224.19500066563486 average time: 123.3 best_reward: 492.5000017359853\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 239.8400007110089 average time: 139.1 best_reward: 421.20000172406435\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 236.54000078402458 average time: 138.55 best_reward: 444.5000018104911\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 238.28500062823295 average time: 139.15 best_reward: 488.5000010058284\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 210.61500063315034 average time: 122.95 best_reward: 415.7000023648143\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 241.9300005033612 average time: 174.5 best_reward: 416.10000060498714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 172.4950005494058 average time: 87.1 best_reward: 421.6000020056963\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 221.7500006724149 average time: 107.1 best_reward: 448.0000013932586\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 196.42000052966176 average time: 107.5 best_reward: 528.1000023856759\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 249.04500075653195 average time: 123.8 best_reward: 493.800001911819\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 120000 / 500000\n",
      "average reward: 356.2400012176484 average time: 171.8 best_reward: 985.7000029534101\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 258.7300007082522 average time: 121.1 best_reward: 529.6000021696091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 252.7450009301305 average time: 125.0 best_reward: 448.0000024959445\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 340.92000128030776 average time: 161.8 best_reward: 525.8000015169382\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 347.2450014218688 average time: 157.35 best_reward: 577.8000027909875\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 343.64500135444104 average time: 178.65 best_reward: 728.400002270937\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 180000 / 500000\n",
      "average reward: 415.96000177562235 average time: 180.9 best_reward: 985.7000043541193\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 427.80000192523005 average time: 185.6 best_reward: 726.1000029295683\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 434.5150018531829 average time: 291.65 best_reward: 647.200002759695\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 322.6750013642013 average time: 221.3 best_reward: 647.4000030085444\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 344.2000013325363 average time: 198.7 best_reward: 722.7000036984682\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 290.2200009893626 average time: 157.55 best_reward: 529.700002335012\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 481.0050021670759 average time: 252.95 best_reward: 729.4000034332275\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 361.535001437366 average time: 158.65 best_reward: 596.2000025585294\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 418.8400018505752 average time: 182.85 best_reward: 841.0000039562583\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 417.28500211797655 average time: 171.35 best_reward: 731.3000041022897\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 489.37500204667447 average time: 385.4 best_reward: 731.6000028699636\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 396.90000166222455 average time: 208.65 best_reward: 647.1000030338764\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 455.8200017232448 average time: 247.7 best_reward: 729.0000022873282\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 475.5150020904839 average time: 234.45 best_reward: 757.6000017151237\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 320000 / 500000\n",
      "average reward: 388.95000156164167 average time: 182.25 best_reward: 981.2000034302473\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 330000 / 500000\n",
      "average reward: 459.21000175848604 average time: 218.85 best_reward: 985.3000036627054\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 396.16500189825894 average time: 158.75 best_reward: 730.2000038102269\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 381.3800018388778 average time: 152.9 best_reward: 730.1000043004751\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 381.96000154912474 average time: 276.1 best_reward: 729.7000034600496\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 370000 / 500000\n",
      "average reward: 395.54500166140497 average time: 179.95 best_reward: 984.7000045180321\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 382.6450016785413 average time: 172.3 best_reward: 983.3000051006675\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 502.04000200629235 average time: 230.7 best_reward: 984.3000013232231\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 400000 / 500000\n",
      "average reward: 571.0100021570921 average time: 302.2 best_reward: 985.1000023037195\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 347.4100012883544 average time: 179.15 best_reward: 986.2000037804246\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 516.0650021586567 average time: 236.1 best_reward: 983.9000042304397\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 430000 / 500000\n",
      "average reward: 498.5050021611154 average time: 243.6 best_reward: 984.000003285706\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 379.7600015010685 average time: 181.9 best_reward: 984.5000015646219\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 320.4400012809783 average time: 317.35 best_reward: 722.1000030264258\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 429.60000166222454 average time: 293.35 best_reward: 980.9000033065677\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 412.42500177249315 average time: 208.0 best_reward: 977.0000035911798\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 637.5900028176605 average time: 314.95 best_reward: 985.6000061407685\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 400.7800017055124 average time: 197.9 best_reward: 811.700003258884\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 414.5250017881393 average time: 226.0 best_reward: 814.500004440546\n"
     ]
    }
   ],
   "source": [
    "train('./Intrins', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, intrins_reward = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67022f3e-1efa-49ca-8d19-026c0eae0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 288.07000064961613 average time: 219.7 best_reward: 727.5000011846423\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 237.25500032901763 average time: 201.65 best_reward: 414.69999987632036\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 260.11500032693147 average time: 186.95 best_reward: 419.49999929219484\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 240.46000057049096 average time: 139.4 best_reward: 576.6000024750829\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 242.23500066027046 average time: 150.85 best_reward: 524.6000018343329\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 214.16000049486757 average time: 130.65 best_reward: 491.00000102072954\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 218.4900007493794 average time: 105.0 best_reward: 492.00000128149986\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 226.49500074088573 average time: 134.7 best_reward: 447.1000027731061\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 277.64000082351265 average time: 155.35 best_reward: 576.1000031158328\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 252.330000660941 average time: 129.9 best_reward: 595.2000011876225\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 110000 / 500000\n",
      "average reward: 325.2450008101761 average time: 196.65 best_reward: 983.5000007748604\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 215.7100004926324 average time: 120.0 best_reward: 595.9000021889806\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 130000 / 500000\n",
      "average reward: 334.7250009972602 average time: 194.45 best_reward: 984.5000036507845\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 281.0500008951873 average time: 143.35 best_reward: 526.7000021710992\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 289.1450007263571 average time: 152.1 best_reward: 492.6000018417835\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 300.1600008998066 average time: 153.2 best_reward: 594.5000027641654\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 306.990000872314 average time: 152.7 best_reward: 596.400002323091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 231.60500079020858 average time: 117.15 best_reward: 422.80000173300505\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 269.9900008182973 average time: 129.45 best_reward: 492.70000222325325\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 301.26500116474926 average time: 143.1 best_reward: 528.400002554059\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 351.5150013323873 average time: 157.6 best_reward: 577.5000011473894\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 369.61000138409435 average time: 166.95 best_reward: 602.4000029265881\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 383.25000138171015 average time: 176.05 best_reward: 730.7000034078956\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 357.08000150434674 average time: 151.2 best_reward: 731.1000031083822\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 506.89500222019853 average time: 203.65 best_reward: 815.7000030055642\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 453.04500218331816 average time: 186.55 best_reward: 727.000003375113\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 446.0750020124018 average time: 186.5 best_reward: 815.8000032901764\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 448.1700020618737 average time: 173.85 best_reward: 731.0000034719706\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 482.2400021318346 average time: 196.15 best_reward: 814.3000030145049\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 493.12000240720806 average time: 191.4 best_reward: 731.6000032871962\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 446.6900018937886 average time: 180.05 best_reward: 730.9000029340386\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 355.14000168964265 average time: 136.3 best_reward: 730.9000028222799\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 330000 / 500000\n",
      "average reward: 454.335002014786 average time: 181.05 best_reward: 987.0000037699938\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 481.34500218145547 average time: 186.95 best_reward: 811.3000031933188\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 350000 / 500000\n",
      "average reward: 464.1800020672381 average time: 180.2 best_reward: 985.500003054738\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 414.84000174477694 average time: 173.4 best_reward: 986.1000047326088\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 464.41000209972265 average time: 186.5 best_reward: 810.0000033825636\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 384.365001751855 average time: 160.6 best_reward: 730.000003516674\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 600.5200026821345 average time: 244.15 best_reward: 815.6000039055943\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 400000 / 500000\n",
      "average reward: 555.4950022131204 average time: 228.1 best_reward: 986.7000020891428\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 410000 / 500000\n",
      "average reward: 532.5200022328645 average time: 221.95 best_reward: 986.8000013232231\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 553.8000023368746 average time: 230.6 best_reward: 987.100003734231\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 405.7700018800795 average time: 152.1 best_reward: 596.8000030368567\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 464.1250019669533 average time: 205.05 best_reward: 808.7000027820468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 550.1650025952607 average time: 219.85 best_reward: 815.6000042557716\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 456.83000181466343 average time: 191.7 best_reward: 815.5000028833747\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 540.9050022851676 average time: 216.55 best_reward: 986.0000031739473\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 468.7250018998981 average time: 216.55 best_reward: 814.4000033438206\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 546.9950025964529 average time: 219.95 best_reward: 986.500003054738\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 488.4350020624697 average time: 205.35 best_reward: 814.40000333637\n"
     ]
    }
   ],
   "source": [
    "#train('./Annealing', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, annealing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbb92a4-a5be-49d8-8940-33292e55ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 231.8850003749132 average time: 189.55 best_reward: 487.0000003054738\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 249.02000081017613 average time: 136.75 best_reward: 492.20000091940165\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 245.8550007712096 average time: 137.25 best_reward: 524.600001975894\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 323.99000112600623 average time: 182.85 best_reward: 492.20000103861094\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 210.9550007622689 average time: 96.6 best_reward: 447.30000127106905\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 222.15500076636673 average time: 101.0 best_reward: 577.3000015467405\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 249.3450008071959 average time: 120.0 best_reward: 492.9000024497509\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 409.9150015767664 average time: 180.3 best_reward: 728.6000029593706\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 307.09500102065505 average time: 147.95 best_reward: 576.4000015854836\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 461.6900016833097 average time: 201.5 best_reward: 729.500003091991\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 404.42000161260364 average time: 177.2 best_reward: 594.6000007092953\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 120000 / 500000\n",
      "average reward: 433.7500017017126 average time: 202.2 best_reward: 983.0000004470348\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 465.1800020992756 average time: 196.75 best_reward: 729.6000025868416\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 449.28500206544993 average time: 193.6 best_reward: 814.7000042274594\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 150000 / 500000\n",
      "average reward: 316.6350011661649 average time: 136.35 best_reward: 985.7000049129128\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 399.56000176519154 average time: 165.45 best_reward: 731.0000027641654\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 170000 / 500000\n",
      "average reward: 519.5700022466481 average time: 248.3 best_reward: 987.4000021219254\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 180000 / 500000\n",
      "average reward: 490.4700018823147 average time: 273.6 best_reward: 986.7000025585294\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 190000 / 500000\n",
      "average reward: 567.9600022938102 average time: 252.1 best_reward: 986.7000036984682\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 200000 / 500000\n",
      "average reward: 377.05500145182015 average time: 154.4 best_reward: 985.9000054076314\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 210000 / 500000\n",
      "average reward: 547.9800025474281 average time: 234.65 best_reward: 986.500006057322\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 220000 / 500000\n",
      "average reward: 617.3050024610013 average time: 356.7 best_reward: 987.3000031560659\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 230000 / 500000\n",
      "average reward: 333.2950013950467 average time: 177.75 best_reward: 986.4000043869019\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 264.26000119559467 average time: 134.8 best_reward: 729.3000025600195\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 250000 / 500000\n",
      "average reward: 394.8500021502376 average time: 230.9 best_reward: 978.1000060364604\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 260000 / 500000\n",
      "average reward: 446.1850015502423 average time: 346.55 best_reward: 977.799999922514\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 270000 / 500000\n",
      "average reward: 591.1850021705031 average time: 418.25 best_reward: 984.600002489984\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 280000 / 500000\n",
      "average reward: 573.1600022483617 average time: 322.05 best_reward: 981.3000022172928\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 290000 / 500000\n",
      "average reward: 594.8600027736277 average time: 255.55 best_reward: 986.9000039696693\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 300000 / 500000\n",
      "average reward: 505.2750021297485 average time: 239.95 best_reward: 986.500002630055\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 310000 / 500000\n",
      "average reward: 430.42000175751747 average time: 185.75 best_reward: 986.5000027343631\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 320000 / 500000\n",
      "average reward: 633.9150026287883 average time: 279.7 best_reward: 986.2000050246716\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 446.745002085343 average time: 256.85 best_reward: 810.2000031396747\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 635.2750029820949 average time: 284.25 best_reward: 986.1000023186207\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 350000 / 500000\n",
      "average reward: 507.4850022062659 average time: 336.1 best_reward: 986.4000033140182\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 360000 / 500000\n",
      "average reward: 508.515002143383 average time: 411.9 best_reward: 987.0000045150518\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 582.0750028755516 average time: 292.7 best_reward: 814.9000035449862\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 544.23000237979 average time: 225.35 best_reward: 985.8000036403537\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 390000 / 500000\n",
      "average reward: 578.7350027877837 average time: 240.8 best_reward: 985.9000052511692\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 284.62500145249066 average time: 285.7 best_reward: 727.8000036627054\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 367.0650017891079 average time: 236.1 best_reward: 721.9000029563904\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 420000 / 500000\n",
      "average reward: 618.5600031677634 average time: 254.0 best_reward: 985.9000053852797\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 430000 / 500000\n",
      "average reward: 621.6850028775632 average time: 258.35 best_reward: 986.7000060677528\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 549.2850022230298 average time: 263.6 best_reward: 986.6000032946467\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 450000 / 500000\n",
      "average reward: 650.9600029785186 average time: 296.6 best_reward: 987.5000056475401\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 680.0450029108673 average time: 294.3 best_reward: 988.1000053733587\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 626.8150028724224 average time: 335.8 best_reward: 987.4000047445297\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 838.4450035192073 average time: 369.9 best_reward: 987.2000064477324\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 471.77500228099524 average time: 492.1 best_reward: 983.200003914535\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 438.5550016835332 average time: 492.05 best_reward: 870.1000035703182\n"
     ]
    }
   ],
   "source": [
    "train('./ValueClip', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, value_clip = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a87f26-61fd-401d-a8d2-94b6ea8062ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 288.38000058196485 average time: 276.5 best_reward: 726.0000014230609\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 206.610000423342 average time: 425.25 best_reward: 259.20000118017197\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 181.4900003861636 average time: 114.9 best_reward: 336.8000005632639\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 243.54000078924 average time: 137.65 best_reward: 420.6000023409724\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 307.3350009750575 average time: 177.65 best_reward: 729.5000011846423\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 256.9400007542223 average time: 249.55 best_reward: 572.6000035330653\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 223.66000049449502 average time: 120.8 best_reward: 447.30000223219395\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 287.4200007148087 average time: 155.2 best_reward: 574.7000020816922\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 181.2850004222244 average time: 202.4 best_reward: 447.30000203102827\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 147.355000436306 average time: 72.25 best_reward: 418.4000005275011\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 265.33000061921774 average time: 149.65 best_reward: 577.8000013008714\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 248.49000061228872 average time: 139.9 best_reward: 528.4000014588237\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 338.2850010313094 average time: 174.25 best_reward: 592.2000017985702\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 211.00500062443317 average time: 115.2 best_reward: 420.5000009611249\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 224.12500071562826 average time: 116.7 best_reward: 422.90000193566084\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 227.1800007071346 average time: 122.7 best_reward: 419.6000010073185\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 225.76500055342913 average time: 142.0 best_reward: 329.20000141113997\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 232.08500046283007 average time: 122.45 best_reward: 594.6000015735626\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 296.64000072441996 average time: 171.45 best_reward: 447.7000018656254\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 252.8850005067885 average time: 132.1 best_reward: 575.9000022783875\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 227.76500071845948 average time: 117.05 best_reward: 447.2000005543232\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 218.78500078991055 average time: 93.75 best_reward: 448.4000022262335\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 217.70500061176716 average time: 119.25 best_reward: 529.6000026389956\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 244.1800005197525 average time: 136.4 best_reward: 420.2000009790063\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 256.5300007611513 average time: 140.95 best_reward: 526.9000026360154\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 260.68500092998147 average time: 142.0 best_reward: 491.70000183582306\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 211.6350006107241 average time: 110.2 best_reward: 446.8000019714236\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 237.35000058785081 average time: 124.0 best_reward: 526.700001463294\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 273.13500078693033 average time: 145.3 best_reward: 575.8000000342727\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 298.99500095546244 average time: 165.85 best_reward: 730.1000019684434\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 211.19500066675246 average time: 105.1 best_reward: 421.4000014141202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train('./Base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0a20fc-8330-42ac-8bd9-3e6a0b1377c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 173.18000011518598 average time: 279.5 best_reward: 259.8000006452203\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 261.5950005244464 average time: 393.05 best_reward: 486.5000009909272\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 243.4550005823374 average time: 435.9 best_reward: 480.80000112205744\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 177.2300003156066 average time: 464.2 best_reward: 253.40000077337027\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 229.73000053949653 average time: 300.9 best_reward: 440.40000151097775\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 208.33000042624772 average time: 248.65 best_reward: 326.8999999240041\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 198.72000039741397 average time: 479.85 best_reward: 410.2000001966953\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 192.4550003003329 average time: 165.4 best_reward: 414.9999999254942\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 240.68500054888426 average time: 267.65 best_reward: 527.5000018030405\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 249.89500053115188 average time: 228.85 best_reward: 724.2000013589859\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 326.2800006389618 average time: 208.8 best_reward: 592.4000023901463\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 268.8500005979091 average time: 190.9 best_reward: 594.2000019848347\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 237.78500034362077 average time: 174.3 best_reward: 490.9000015631318\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 249.98000071309508 average time: 148.4 best_reward: 525.0000023394823\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 237.36500038169325 average time: 148.55 best_reward: 417.5000008121133\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 250.51000062003732 average time: 127.45 best_reward: 529.9000017866492\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 170000 / 500000\n",
      "average reward: 328.48500082567335 average time: 205.55 best_reward: 980.5000050589442\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 273.8400009475648 average time: 157.8 best_reward: 517.3000026866794\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 263.1800006058067 average time: 137.75 best_reward: 421.20000045001507\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 266.9000007811934 average time: 154.8 best_reward: 489.6000000461936\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 280.035000616312 average time: 151.85 best_reward: 448.4000018015504\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 207.68500059582294 average time: 118.4 best_reward: 420.5000018104911\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 274.9150007311255 average time: 178.05 best_reward: 858.1000023111701\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 252.71000082306563 average time: 139.6 best_reward: 421.5000014305115\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 256.885000840202 average time: 125.95 best_reward: 530.1000024452806\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 220.94500056318938 average time: 124.7 best_reward: 420.4000016003847\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 283.8150007832795 average time: 147.55 best_reward: 422.70000134408474\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 271.150000718981 average time: 144.75 best_reward: 490.8000004813075\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 320.3750008098781 average time: 162.8 best_reward: 728.3000018596649\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 250.51500053554773 average time: 137.75 best_reward: 447.5000017285347\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 244.1500006586313 average time: 133.0 best_reward: 525.4000023975968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 216.07000078074634 average time: 115.1 best_reward: 534.6000017672777\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 230.1700007136911 average time: 112.2 best_reward: 526.8000006303191\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 285.7900006607175 average time: 153.65 best_reward: 526.3000015765429\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 256.40000088177624 average time: 129.6 best_reward: 525.2000025734305\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 282.1550007518381 average time: 144.45 best_reward: 576.1000012978911\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 257.99500074721874 average time: 135.75 best_reward: 443.0000018328428\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 280.8050008870661 average time: 152.8 best_reward: 577.0000011771917\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 198.43500073365868 average time: 99.0 best_reward: 447.3000019490719\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 220.07500084452332 average time: 114.7 best_reward: 419.00000121444464\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 233.27000055611134 average time: 119.1 best_reward: 493.00000187009573\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 216.55000061541796 average time: 104.15 best_reward: 577.4000013768673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 251.6650007277727 average time: 118.4 best_reward: 493.6000020131469\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 440000 / 500000\n",
      "average reward: 294.09000086411834 average time: 162.8 best_reward: 983.0000026002526\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 309.785000917688 average time: 169.3 best_reward: 728.8000035136938\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 227.5050006262958 average time: 114.9 best_reward: 447.10000232607126\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 261.5800006330013 average time: 128.2 best_reward: 492.4000016152859\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 296.96500071696937 average time: 150.3 best_reward: 985.1000001356006\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 253.82000084109603 average time: 126.45 best_reward: 728.9000039920211\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 261.5500008635223 average time: 133.05 best_reward: 529.800002463162\n"
     ]
    }
   ],
   "source": [
    "train('./VNet[64,64]', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, arch=[64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88892a31-cef6-4cc2-8b2c-1c604b55f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 207.95500070527197 average time: 115.5 best_reward: 419.6000012680888\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 256.79000087827444 average time: 129.65 best_reward: 575.4000009074807\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 30000 / 500000\n",
      "average reward: 288.2800005801022 average time: 201.45 best_reward: 979.0000011846423\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 288.3150007288903 average time: 183.3 best_reward: 524.4000019803643\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 200.5550004079938 average time: 123.4 best_reward: 422.00000098347664\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 216.8200006082654 average time: 137.1 best_reward: 444.2000008299947\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 250.2700007099658 average time: 132.05 best_reward: 492.10000175982714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 213.33000051118432 average time: 123.95 best_reward: 491.9000026807189\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 254.21500071212648 average time: 139.75 best_reward: 728.500002682209\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 263.0700006943196 average time: 137.25 best_reward: 420.400001116097\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 201.94500058367848 average time: 100.9 best_reward: 729.0000024363399\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 179.64000054039062 average time: 93.05 best_reward: 529.8000011816621\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 226.69500061534345 average time: 127.3 best_reward: 523.8000020831823\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 270.5450005616993 average time: 175.55 best_reward: 527.6000021845102\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 251.46000061966478 average time: 133.05 best_reward: 493.00000186264515\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 264.7700008146465 average time: 131.7 best_reward: 492.10000156611204\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 215.26500055342913 average time: 107.55 best_reward: 492.50000208616257\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 245.23500073812903 average time: 137.45 best_reward: 493.30000139027834\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 215.16500069387257 average time: 104.7 best_reward: 448.90000253915787\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 254.31500076651574 average time: 146.1 best_reward: 813.6000013276935\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 238.67500058822333 average time: 137.55 best_reward: 447.0000017955899\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 265.46000070236624 average time: 145.2 best_reward: 529.3000023663044\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 255.11000076532363 average time: 130.15 best_reward: 575.300001449883\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 290.3700007684529 average time: 152.4 best_reward: 529.6000019088387\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 206.99500076361 average time: 105.2 best_reward: 421.20000164955854\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 260000 / 500000\n",
      "average reward: 246.23500065281988 average time: 124.3 best_reward: 983.0000001937151\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 249.3800005313009 average time: 131.2 best_reward: 492.2000022009015\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 211.91000048108398 average time: 134.35 best_reward: 420.200000166893\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 203.30000056512654 average time: 94.6 best_reward: 421.7000011205673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 251.10000055767597 average time: 144.45 best_reward: 416.80000028014183\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 240.70000052303075 average time: 134.0 best_reward: 418.3000012487173\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 226.65000064224006 average time: 109.25 best_reward: 730.1000026538968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 231.6800008494407 average time: 113.2 best_reward: 525.1000019684434\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 213.56500043831767 average time: 115.6 best_reward: 577.5000026747584\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 260.235000821203 average time: 147.5 best_reward: 446.40000204741955\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 290.7750009037554 average time: 151.65 best_reward: 577.4000013098121\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 250.61000071018935 average time: 133.1 best_reward: 728.4000013545156\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 315.345000821352 average time: 155.2 best_reward: 576.4000013396144\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 259.4550005991012 average time: 151.45 best_reward: 448.3000013977289\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 263.81000086404384 average time: 135.9 best_reward: 528.6000008434057\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 304.74500081688166 average time: 162.05 best_reward: 524.5000022947788\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 251.79000069089233 average time: 130.15 best_reward: 444.80000177025795\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 247.97500079534947 average time: 132.7 best_reward: 526.500001899898\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 202.45000070892274 average time: 100.5 best_reward: 488.90000239759684\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 283.4800008755177 average time: 138.3 best_reward: 447.9000019952655\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 243.53500077053906 average time: 119.15 best_reward: 527.500001296401\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 295.1600009121001 average time: 154.15 best_reward: 595.600001744926\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 263.0700007904321 average time: 140.95 best_reward: 447.60000202059746\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 262.29500075690447 average time: 120.4 best_reward: 493.8000020161271\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 323.0950011450797 average time: 155.0 best_reward: 727.6000027135015\n"
     ]
    }
   ],
   "source": [
    "train('./VNet[32,32,32,32]', activation_function = torch.nn.Tanh, grad_norm = 0.5, orthagonal_init=True, arch=[32, 32, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b05c153-f7bd-41b7-8ec8-1af7a5654e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 245.2950005337596 average time: 269.0 best_reward: 511.70000094920397\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 20000 / 500000\n",
      "average reward: 289.04000062793494 average time: 271.85 best_reward: 978.2000025436282\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 252.87000058107077 average time: 222.1 best_reward: 569.2000020816922\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 212.68500047028064 average time: 301.0 best_reward: 327.1000012084842\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 295.46000070124865 average time: 270.25 best_reward: 726.2000005766749\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 224.8600003849715 average time: 179.25 best_reward: 725.5000002533197\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 239.28500054478644 average time: 190.2 best_reward: 438.5999996587634\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 210.45500038824974 average time: 128.7 best_reward: 420.3000019341707\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 259.52500072531404 average time: 132.2 best_reward: 531.800002194941\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 271.73000083975495 average time: 154.4 best_reward: 729.9000034630299\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 240.51000066325068 average time: 124.85 best_reward: 492.40000224113464\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 219.53500062562526 average time: 105.95 best_reward: 491.60000117868185\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 130000 / 500000\n",
      "average reward: 286.0300008490682 average time: 152.15 best_reward: 984.0000035911798\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 189.95000052526592 average time: 90.55 best_reward: 527.8000024184585\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 235.59000053219498 average time: 115.25 best_reward: 448.4000022113323\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 219.40000069588422 average time: 106.45 best_reward: 492.6000009700656\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 265.5300007238984 average time: 141.2 best_reward: 447.6000018119812\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 237.41500096842645 average time: 113.6 best_reward: 528.0000020340085\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 245.5750005956739 average time: 142.6 best_reward: 524.9000002965331\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 251.56500077322124 average time: 130.75 best_reward: 593.5000018402934\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 242.45000081323087 average time: 127.95 best_reward: 446.60000216960907\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 199.09000046662987 average time: 102.95 best_reward: 492.1000013947487\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 187.67000027559698 average time: 106.1 best_reward: 413.80000100284815\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 214.77500050440432 average time: 102.6 best_reward: 448.1000006124377\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 208.6950004156679 average time: 111.15 best_reward: 448.5000006556511\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 303.8700009837747 average time: 157.5 best_reward: 594.900001950562\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 200.92500062584878 average time: 100.55 best_reward: 492.70000184327364\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 232.43500062562526 average time: 126.05 best_reward: 443.9000023007393\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 246.7950007468462 average time: 137.05 best_reward: 419.7000018134713\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 247.48500074334441 average time: 121.35 best_reward: 524.1000012531877\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 222.30500054620205 average time: 122.8 best_reward: 491.80000226199627\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 261.5100009586662 average time: 128.45 best_reward: 582.6000014841557\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 275.00000069327655 average time: 146.75 best_reward: 528.8000012785196\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 294.9100009355694 average time: 155.15 best_reward: 814.2000034153461\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 226.87000068947674 average time: 119.65 best_reward: 491.9000019878149\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 201.03000059872866 average time: 108.3 best_reward: 420.30000073462725\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 211.83500072062014 average time: 115.85 best_reward: 421.80000145733356\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 306.19000108502803 average time: 165.25 best_reward: 983.8000031709671\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 226.285000577569 average time: 130.6 best_reward: 728.1000013202429\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 223.0600006263703 average time: 123.3 best_reward: 493.0000015795231\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 271.3400006365031 average time: 139.9 best_reward: 448.7000020444393\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 295.70000078827144 average time: 160.4 best_reward: 493.50000187009573\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 278.23000080771743 average time: 161.25 best_reward: 576.4000017642975\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 252.0050005685538 average time: 130.75 best_reward: 595.9000005424023\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 353.40000093206766 average time: 181.85 best_reward: 596.4000025764108\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 218.00500074885787 average time: 116.9 best_reward: 493.10000175982714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 212.60000053048134 average time: 113.25 best_reward: 421.4000013694167\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 256.8950007259846 average time: 134.3 best_reward: 572.3000011220574\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 271.49000077098606 average time: 139.3 best_reward: 447.9000021442771\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 283.18000096678736 average time: 143.55 best_reward: 448.100002579391\n"
     ]
    }
   ],
   "source": [
    "train('./VNet[64,64,64,64]', activation_function = torch.nn.Tanh, grad_norm = 0.5, orthagonal_init=True, arch=[64, 64, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ccb777a-704d-4fac-be8f-d45e44226950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 227.5650004874915 average time: 213.35 best_reward: 585.9000025242567\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 265.975000404194 average time: 317.8 best_reward: 575.4000008404255\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 198.7950004402548 average time: 147.8 best_reward: 411.3000011742115\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 257.1700006406754 average time: 214.2 best_reward: 489.9000018686056\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 276.52500048168 average time: 246.3 best_reward: 446.9000020623207\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 288.1800007570535 average time: 220.6 best_reward: 521.2000013738871\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 70000 / 500000\n",
      "average reward: 291.68000058084726 average time: 188.0 best_reward: 983.2000015825033\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 179.34500042162836 average time: 100.35 best_reward: 364.80000108480453\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 251.2700006816536 average time: 139.8 best_reward: 449.0000007972121\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 288.41000088378786 average time: 156.3 best_reward: 534.700001321733\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 233.24000054709614 average time: 122.5 best_reward: 448.6000016257167\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 230.26500066183507 average time: 119.2 best_reward: 529.6000019237399\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 245.2650003861636 average time: 160.65 best_reward: 420.7000003159046\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 242.56500055007638 average time: 138.45 best_reward: 595.100002206862\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 190.3450004581362 average time: 98.5 best_reward: 448.5000018849969\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 276.1800006732345 average time: 153.55 best_reward: 814.4000019058585\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 233.03000073768197 average time: 124.05 best_reward: 420.8000016286969\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 232.3250004801899 average time: 136.35 best_reward: 418.90000220388174\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 261.19000062979757 average time: 153.85 best_reward: 525.8000022396445\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 211.35000037401915 average time: 127.65 best_reward: 413.7000010237098\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 181.13500043302776 average time: 100.8 best_reward: 421.1000021472573\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 281.35500079914925 average time: 151.7 best_reward: 493.3000023290515\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 280.34000078476964 average time: 161.45 best_reward: 448.0000019520521\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 240.4750007059425 average time: 129.45 best_reward: 728.0000022575259\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 245.0550009354949 average time: 119.15 best_reward: 596.7000032737851\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 273.92500066831707 average time: 165.65 best_reward: 596.9000015705824\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 331.700000776723 average time: 204.05 best_reward: 813.100001566112\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 268.07500053718684 average time: 156.05 best_reward: 448.9000009149313\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 256.47000067681074 average time: 137.75 best_reward: 575.5000017136335\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 240.99500071145593 average time: 131.95 best_reward: 447.20000173151493\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 242.04000073745846 average time: 132.55 best_reward: 529.4000026285648\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 203.13000059872866 average time: 107.0 best_reward: 447.80000173300505\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 239.05000067725777 average time: 134.45 best_reward: 595.4000020325184\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 340000 / 500000\n",
      "average reward: 281.6100007712841 average time: 137.3 best_reward: 985.0000031739473\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 227.2150007236749 average time: 133.85 best_reward: 422.40000136196613\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 240.80500068366527 average time: 129.05 best_reward: 421.3000011071563\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 232.51500062271953 average time: 121.6 best_reward: 530.0000020712614\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 234.37500054277479 average time: 123.6 best_reward: 447.7000014334917\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 277.3550007957965 average time: 149.45 best_reward: 494.3000015541911\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 284.96000089347365 average time: 149.45 best_reward: 529.8000025823712\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 246.56500076279045 average time: 127.85 best_reward: 490.9000002220273\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 265.2650007724762 average time: 146.85 best_reward: 446.80000103265047\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 208.6500006016344 average time: 114.65 best_reward: 422.8000020161271\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 239.10000061765314 average time: 125.15 best_reward: 529.7000012844801\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 203.99500061161817 average time: 107.65 best_reward: 420.2000015601516\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 257.0950004316866 average time: 147.95 best_reward: 447.9000013023615\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 297.0150007143617 average time: 148.45 best_reward: 524.5000009387732\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 234.4950005557388 average time: 120.4 best_reward: 421.50000067055225\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 272.5650007579476 average time: 151.15 best_reward: 491.50000189989805\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 244.24500032179057 average time: 142.95 best_reward: 528.3000007942319\n"
     ]
    }
   ],
   "source": [
    "train('./NoneExtractor2', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, feature_extractor = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad54c9c-948b-40d2-908d-2c6aceeaf9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 219.63500059992074 average time: 179.3 best_reward: 356.6999997422099\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 202.3800007712096 average time: 108.55 best_reward: 421.9000006765127\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 206.72000068128108 average time: 125.95 best_reward: 726.2000026777387\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 165.18000051267444 average time: 94.1 best_reward: 523.7000019773841\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 226.60500067807735 average time: 139.35 best_reward: 419.0000016093254\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 232.8700008813292 average time: 125.45 best_reward: 528.6000013574958\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 245.98000070266426 average time: 164.3 best_reward: 726.1000029966235\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 238.04500062130393 average time: 130.05 best_reward: 524.000000692904\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 171.69000042639672 average time: 90.85 best_reward: 419.2000010833144\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 183.6400005992502 average time: 106.05 best_reward: 490.2000020071864\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 212.3100003942847 average time: 116.1 best_reward: 421.40000100433826\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 241.03000084161758 average time: 119.6 best_reward: 525.4000021740794\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 195.33500046655536 average time: 105.35 best_reward: 446.7000013515353\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 287.6900005567819 average time: 159.7 best_reward: 812.6000006124377\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 324.6250007405877 average time: 183.1 best_reward: 813.9000028371811\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 232.505000622198 average time: 110.0 best_reward: 728.6000023707747\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 209.2900006622076 average time: 105.35 best_reward: 729.2000007480383\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 231.6900008559227 average time: 111.3 best_reward: 597.4000027626753\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 194.64500062130392 average time: 96.4 best_reward: 329.6000007838011\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 206.2000006444752 average time: 99.05 best_reward: 448.2000021710992\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 224.63500074595214 average time: 111.1 best_reward: 413.8000005632639\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 290.55500099845233 average time: 143.25 best_reward: 492.6000030115247\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 247.7650006387383 average time: 123.45 best_reward: 493.4000021368265\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 279.8000008393079 average time: 146.8 best_reward: 492.4000026360154\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 254.42500070184468 average time: 130.4 best_reward: 448.40000227838755\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 216.51500066146255 average time: 101.15 best_reward: 421.0000016465783\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 256.185000757128 average time: 127.95 best_reward: 444.60000095516443\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 353.11000129655 average time: 173.25 best_reward: 813.900002092123\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 290000 / 500000\n",
      "average reward: 245.99000088833273 average time: 111.55 best_reward: 985.7000043988228\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 292.68500113487244 average time: 131.9 best_reward: 577.700002476573\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 237.8650006234646 average time: 112.45 best_reward: 492.40000250935555\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 283.0800011042505 average time: 130.5 best_reward: 596.9000031650066\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 297.64000123143194 average time: 136.55 best_reward: 493.1000020727515\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 281.81000079885126 average time: 127.35 best_reward: 596.4000017940998\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 261.67000085823236 average time: 121.35 best_reward: 489.7000025212765\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 318.67000127621 average time: 148.2 best_reward: 525.3000024557114\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 358.1300012044609 average time: 167.3 best_reward: 597.9000029265881\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 266.5050008725375 average time: 123.0 best_reward: 577.5000022947788\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 293.6900008685887 average time: 151.9 best_reward: 728.900001630187\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 294.59500098824503 average time: 141.4 best_reward: 576.5000030770898\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 394.92500167787074 average time: 184.45 best_reward: 730.4000022634864\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 256.9750008173287 average time: 117.3 best_reward: 573.5000020265579\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 283.8000010877848 average time: 120.1 best_reward: 529.700002387166\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 337.09000107832253 average time: 156.3 best_reward: 600.9000018462539\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 450000 / 500000\n",
      "average reward: 297.33000106438993 average time: 135.15 best_reward: 985.000001296401\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 279.6700009837747 average time: 126.75 best_reward: 728.9000019654632\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 470000 / 500000\n",
      "average reward: 320.1350008945912 average time: 140.45 best_reward: 986.8000035881996\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 480000 / 500000\n",
      "average reward: 364.28000144287944 average time: 163.0 best_reward: 986.0000045150518\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 310.6800011169165 average time: 144.6 best_reward: 577.6000030115247\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 311.78500105701386 average time: 138.4 best_reward: 576.1000020131469\n"
     ]
    }
   ],
   "source": [
    "train('./NoneExtractor3', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5,feature_extractor = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5882e70-56c3-4748-8383-b95c43148c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 257.75000074729326 average time: 242.3 best_reward: 490.7000028267503\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 217.6450003363192 average time: 228.8 best_reward: 526.2000024169683\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 251.15500066541136 average time: 179.45 best_reward: 489.90000104904175\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 242.61500064842403 average time: 147.85 best_reward: 491.80000199377537\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 237.23000080399214 average time: 132.65 best_reward: 523.9000019207597\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 268.3600005470216 average time: 185.25 best_reward: 420.9000017642975\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 227.23000066876412 average time: 121.65 best_reward: 447.6000014692545\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 193.10500054769219 average time: 100.55 best_reward: 446.8000023961067\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 265.3100007805973 average time: 137.8 best_reward: 492.60000222176313\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 230.61000062189996 average time: 125.05 best_reward: 492.0000016465783\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 204.985000590235 average time: 113.8 best_reward: 492.0000007599592\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 241.60000087767838 average time: 121.7 best_reward: 447.60000244528055\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 272.7950006771833 average time: 148.5 best_reward: 525.7000019028783\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 246.2550007980317 average time: 145.7 best_reward: 572.7000015452504\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 228.98500042520465 average time: 140.2 best_reward: 488.50000035762787\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 209.99500065669417 average time: 108.95 best_reward: 419.8000010550022\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 214.20500041656197 average time: 130.25 best_reward: 419.40000154078007\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 250.7650008250028 average time: 161.25 best_reward: 813.600003361702\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 190000 / 500000\n",
      "average reward: 234.01000082716345 average time: 139.85 best_reward: 984.7000063285232\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 225.920000866428 average time: 122.8 best_reward: 577.2000022754073\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 205.26500060036778 average time: 107.75 best_reward: 527.1000011712313\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 208.91000039987267 average time: 117.45 best_reward: 446.9000018015504\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 269.3200006324798 average time: 176.25 best_reward: 490.3000016063452\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 265.945000576973 average time: 158.95 best_reward: 529.2999997660518\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 286.86000055633485 average time: 175.6 best_reward: 571.9000020027161\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 289.5950004979968 average time: 192.15 best_reward: 720.4000004455447\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 220.54500035904348 average time: 136.85 best_reward: 524.6000006943941\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 291.34000066034497 average time: 220.55 best_reward: 593.1000024601817\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 305.025000410527 average time: 195.3 best_reward: 727.8000000566244\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 300000 / 500000\n",
      "average reward: 302.1900010060519 average time: 162.6 best_reward: 982.7000025957823\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 235.2450004581362 average time: 156.2 best_reward: 489.80000118911266\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 262.82500049471855 average time: 162.05 best_reward: 571.5000019222498\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 224.6750007186085 average time: 132.35 best_reward: 419.100001655519\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 259.1400004860014 average time: 164.1 best_reward: 487.8000011816621\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 189.1950005799532 average time: 98.3 best_reward: 576.5000017806888\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 231.7800005789846 average time: 130.95 best_reward: 490.70000088214874\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 236.23500046879053 average time: 135.85 best_reward: 447.80000115931034\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 234.33000048398972 average time: 137.5 best_reward: 524.2000019028783\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 213.31500061042607 average time: 114.35 best_reward: 487.10000067204237\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 400000 / 500000\n",
      "average reward: 280.06500070914626 average time: 161.4 best_reward: 985.6000041142106\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 234.44000061452388 average time: 135.1 best_reward: 595.4000006094575\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 275.03500078991055 average time: 155.85 best_reward: 524.4000015109777\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 232.25000051669775 average time: 161.35 best_reward: 420.90000170469284\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 244.22000035196544 average time: 155.75 best_reward: 446.90000155568123\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 450000 / 500000\n",
      "average reward: 313.98000089116397 average time: 165.85 best_reward: 985.6000030636787\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 226.9350005108863 average time: 134.85 best_reward: 530.1000025942922\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 196.8000004760921 average time: 116.8 best_reward: 443.500001527369\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 293.11500072032214 average time: 161.15 best_reward: 727.5000006631017\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 490000 / 500000\n",
      "average reward: 270.175000552088 average time: 169.8 best_reward: 984.2000020071864\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 239.61500063873828 average time: 131.05 best_reward: 422.4000023826957\n"
     ]
    }
   ],
   "source": [
    "train('./VNet[16]', activation_function = torch.nn.Tanh, grad_norm = 0.5, orthagonal_init=True, arch=[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fd7c94-6682-49d9-a4d2-78b747ecf174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 258.6200002774596 average time: 391.9 best_reward: 415.0000023022294\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 274.4250005282462 average time: 394.75 best_reward: 589.7000009045005\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 278.0500007070601 average time: 279.25 best_reward: 725.6000024750829\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 222.535000718385 average time: 182.75 best_reward: 591.8000022098422\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 229.44000050574542 average time: 173.65 best_reward: 421.80000104755163\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 234.7150006607175 average time: 145.8 best_reward: 419.50000167638063\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 238.550000789389 average time: 123.05 best_reward: 492.100001886487\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 235.66500058732927 average time: 138.4 best_reward: 420.7000007033348\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 194.0500003144145 average time: 111.5 best_reward: 420.50000147521496\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 271.83500066399574 average time: 174.0 best_reward: 446.10000167787075\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 275.06000075004994 average time: 171.75 best_reward: 418.9000014588237\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 234.73000045008956 average time: 148.7 best_reward: 575.6000014469028\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 238.90500052757562 average time: 132.25 best_reward: 420.70000141859055\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 257.13000064343214 average time: 153.0 best_reward: 602.0000017881393\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 290.8250007018447 average time: 176.7 best_reward: 490.70000176131725\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 232.70000038146972 average time: 122.65 best_reward: 420.8000010922551\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 288.19000063464046 average time: 157.9 best_reward: 529.300002232194\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 241.98500059582292 average time: 128.4 best_reward: 575.5000022500753\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 239.3550004441291 average time: 148.3 best_reward: 448.90000089257956\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 248.95500058457256 average time: 153.7 best_reward: 813.5000024065375\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 235.6400005210191 average time: 137.4 best_reward: 420.4000001102686\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 241.19000046662987 average time: 144.65 best_reward: 492.60000128299\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 205.4550004541874 average time: 120.5 best_reward: 487.3999998867512\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 308.5950007379055 average time: 206.5 best_reward: 527.1000028699636\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 253.4750008672476 average time: 141.3 best_reward: 594.8000014051795\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 213.5850008096546 average time: 125.55 best_reward: 418.500002078712\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 261.3300005786121 average time: 159.55 best_reward: 447.70000004023314\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 267.40500069707633 average time: 146.2 best_reward: 422.3000022992492\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 203.69500025175512 average time: 105.95 best_reward: 447.7000004351139\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 229.80000050626694 average time: 121.7 best_reward: 596.900002323091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 206.07500052824616 average time: 103.55 best_reward: 491.5000020042062\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 251.48000054098665 average time: 148.25 best_reward: 525.6000018790364\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 260.5750008188188 average time: 138.85 best_reward: 528.700001180172\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 242.50000053606928 average time: 139.9 best_reward: 573.5000003352761\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 231.98500071428717 average time: 126.25 best_reward: 446.80000099539757\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 240.73000075295568 average time: 128.9 best_reward: 492.1000024601817\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 275.28500081785023 average time: 151.95 best_reward: 528.4000014960766\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 264.9250007968396 average time: 148.9 best_reward: 728.9000027254224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 218.71000058725477 average time: 115.55 best_reward: 447.5000018402934\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 267.3450008202344 average time: 149.75 best_reward: 490.3000008612871\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 213.67500062584878 average time: 114.9 best_reward: 527.9000020995736\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 207.1900005541742 average time: 109.15 best_reward: 415.29999969154596\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 253.15500065088273 average time: 144.5 best_reward: 576.7000018656254\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 251.41500071361662 average time: 123.5 best_reward: 528.6000018641353\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 245.1350007828325 average time: 142.3 best_reward: 525.0000025480986\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 225.3050005953759 average time: 122.65 best_reward: 441.800001449883\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 201.2550006210804 average time: 106.2 best_reward: 420.80000161379576\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 234.94000074453652 average time: 122.85 best_reward: 524.600002348423\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 312.62500083372 average time: 174.0 best_reward: 525.6000014916062\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 268.49500077441337 average time: 142.65 best_reward: 447.70000188052654\n"
     ]
    }
   ],
   "source": [
    "train('./VNet[16, 16]', activation_function = torch.nn.Tanh, grad_norm = 0.5, orthagonal_init=True, arch=[16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952240a0-c282-4557-9269-d3bf1e5ce192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 250.6292176569812 average time: 166.45 best_reward: 532.5334246493876\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 237.2991449583322 average time: 152.65 best_reward: 534.4387546144426\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 237.30986139168962 average time: 175.35 best_reward: 430.111417805776\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 259.3037021904718 average time: 252.95 best_reward: 584.7044986691326\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 232.39283358668908 average time: 161.0 best_reward: 428.29730000160635\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 297.62827633839333 average time: 250.9 best_reward: 602.1543931867927\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 241.2186571329832 average time: 151.05 best_reward: 741.1945324619301\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 224.85016202640253 average time: 143.0 best_reward: 453.90172897838056\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 266.1031419148436 average time: 166.6 best_reward: 500.0919026695192\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 231.6264807689935 average time: 167.15 best_reward: 428.5244296975434\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 288.0927816993441 average time: 162.65 best_reward: 500.0401382185519\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 249.66461908947676 average time: 134.9 best_reward: 430.1065724901855\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 240.0484564027749 average time: 130.35 best_reward: 743.6379246395081\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 267.7300656203646 average time: 149.0 best_reward: 430.2732178159058\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 212.8407712860033 average time: 113.8 best_reward: 500.18449747748673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 228.97754310565068 average time: 123.0 best_reward: 536.0463658720255\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 229.57562958411873 average time: 114.65 best_reward: 453.8442925494164\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 309.13852213586216 average time: 174.45 best_reward: 604.4157771002501\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 278.2518577315379 average time: 156.45 best_reward: 533.2924558650702\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 235.72782669919542 average time: 117.15 best_reward: 603.6223508995026\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 235.16591002708302 average time: 118.5 best_reward: 538.2873369026929\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 269.28675776529127 average time: 145.0 best_reward: 455.0914882309735\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 281.3795295500662 average time: 164.2 best_reward: 455.0385464578867\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 281.9340308061801 average time: 156.95 best_reward: 455.8630446959287\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 252.1639097444713 average time: 131.2 best_reward: 500.747196059674\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 255.38418326932006 average time: 142.55 best_reward: 499.4879583232105\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 230.22653631391003 average time: 120.9 best_reward: 427.4309339839965\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 227.14497218080797 average time: 107.4 best_reward: 534.0373700000346\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 281.9367922356352 average time: 139.2 best_reward: 585.1334953680634\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 231.15222455556506 average time: 122.1 best_reward: 430.1528711486608\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 216.36793741688598 average time: 134.15 best_reward: 426.3343955595046\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 288.2711243405938 average time: 186.25 best_reward: 790.5023526716977\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 228.5780380365439 average time: 127.4 best_reward: 499.39688686840236\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 211.06326617868618 average time: 105.0 best_reward: 454.7995853088796\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 233.47502062460407 average time: 118.85 best_reward: 535.5890652798116\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 261.36147374403663 average time: 145.05 best_reward: 537.2844293639064\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 285.5774566916749 average time: 182.45 best_reward: 500.2683043349534\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 246.3051313912496 average time: 123.65 best_reward: 532.5301053784788\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 202.27645640312693 average time: 101.9 best_reward: 535.8453294429928\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 188.64013804313726 average time: 87.7 best_reward: 584.1982012838125\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 280.13304485860283 average time: 142.95 best_reward: 604.1084400452673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 191.48492719391362 average time: 95.4 best_reward: 428.2184089682996\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 239.23484409493395 average time: 114.1 best_reward: 535.407267536968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 234.43232849715278 average time: 122.25 best_reward: 500.27764736302197\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 227.93841133643872 average time: 121.0 best_reward: 739.6963320877403\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 460000 / 500000\n",
      "average reward: 293.4693839301355 average time: 142.25 best_reward: 1000.7452588472515\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 227.0930449174717 average time: 112.1 best_reward: 537.3706577718258\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 256.00132858753204 average time: 124.5 best_reward: 500.53162740916014\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 268.01947385089005 average time: 140.6 best_reward: 453.9474728386849\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 232.1527953390032 average time: 115.85 best_reward: 499.3076805174351\n"
     ]
    }
   ],
   "source": [
    "train('./yPosReward', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, reward_scheme = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea66de06-611b-4013-bd2c-a7c47365f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./scoreReward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTanh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morthagonal_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_scheme\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/env.py:127\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(save_dir, activation_function, orthagonal_init, grad_norm, value_clip, annealing, intrins_reward, feature_extractor, reward_clip, arch, reward_scheme)\u001b[0m\n\u001b[1;32m    121\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs, \n\u001b[1;32m    122\u001b[0m             tensorboard_log\u001b[38;5;241m=\u001b[39msave_dir, learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE, n_steps\u001b[38;5;241m=\u001b[39mN_STEPS,\n\u001b[1;32m    123\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, n_epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS, gamma\u001b[38;5;241m=\u001b[39mGAMMA, gae_lambda\u001b[38;5;241m=\u001b[39mGAE, \n\u001b[1;32m    124\u001b[0m             ent_coef\u001b[38;5;241m=\u001b[39mENT_COEF, clip_range_vf \u001b[38;5;241m=\u001b[39m value_clip, max_grad_norm \u001b[38;5;241m=\u001b[39m grad_norm, annealing \u001b[38;5;241m=\u001b[39m annealing, intrins_reward \u001b[38;5;241m=\u001b[39m intrins_reward)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOTAL_TIMESTEP_NUMB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/PPO.py:336\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    325\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPPO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/on_policy_algorithm.py:357\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    353\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 357\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/on_policy_algorithm.py:267\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03mNew: Calculate the intrinsic reward and add it to the models rewards\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    266\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs\n\u001b[0;32m--> 267\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintrins_reward:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/vec_transpose.py:95\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 95\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/vec_frame_stack.py:48\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]], np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray, List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],]:\n\u001b[0;32m---> 48\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     observations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackedobs\u001b[38;5;241m.\u001b[39mupdate(observations, dones, infos)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 43\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gym/core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gym/core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/env.py:138\u001b[0m, in \u001b[0;36mSkipFrame.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    136\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip):\n\u001b[0;32m--> 138\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "File \u001b[0;32m/home/ktnelson/MarioRL/rewards_change.py:67\u001b[0m, in \u001b[0;36mScoreBenefitWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     65\u001b[0m delta_score \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_score\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_delta_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_delta_score, delta_score)\n\u001b[0;32m---> 67\u001b[0m reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdelta_score\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_delta_score\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_pos\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_x_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "train('./scoreReward', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, reward_scheme = 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35335233-b812-4abf-9a42-8b205b4197e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 204.025000340119 average time: 330.1 best_reward: 416.3000014796853\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 187.8400004580617 average time: 340.65 best_reward: 417.00000037252903\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 188.16500028707088 average time: 487.6 best_reward: 248.79999942332506\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 207.56500044129788 average time: 388.4 best_reward: 408.60000187158585\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 194.00000046379864 average time: 364.05 best_reward: 417.30000088363886\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 170.13000038191677 average time: 477.5 best_reward: 254.59999948740005\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 218.63500041998924 average time: 448.7 best_reward: 417.50000185519457\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 245.10000059679152 average time: 262.15 best_reward: 491.2000011950731\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 268.645000596717 average time: 240.7 best_reward: 591.5000020489097\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 262.60000059083103 average time: 302.05 best_reward: 416.6000008955598\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 206.1650003902614 average time: 170.05 best_reward: 414.40000104159117\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 264.50000061541795 average time: 186.35 best_reward: 592.9000013023615\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 298.8300007928163 average time: 197.9 best_reward: 728.0000027492642\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 170.91500055789948 average time: 88.6 best_reward: 420.10000143945217\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 242.24000042825938 average time: 135.7 best_reward: 524.5999996438622\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 267.2050007987767 average time: 136.35 best_reward: 493.60000122338533\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 262.9400006424636 average time: 152.4 best_reward: 727.3000018373132\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 241.98000058457257 average time: 126.7 best_reward: 493.0000009611249\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 243.62000059634448 average time: 143.7 best_reward: 445.8000008240342\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 240.40000063814222 average time: 121.7 best_reward: 492.7000029012561\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 201.2400005210191 average time: 108.75 best_reward: 421.2000017762184\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 250.61000068038703 average time: 129.25 best_reward: 529.5000008717179\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 290.08000068627297 average time: 163.5 best_reward: 574.9000013768673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 235.0400005389005 average time: 152.05 best_reward: 491.7000009417534\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 236.2000008482486 average time: 131.5 best_reward: 490.9000019878149\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 271.38500079996885 average time: 149.15 best_reward: 728.4000023156404\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 284.99500090368093 average time: 147.7 best_reward: 522.9000017791986\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 258.5250007737428 average time: 141.55 best_reward: 812.6000028252602\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 220.93500076532365 average time: 122.95 best_reward: 493.20000207424164\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 244.7550003528595 average time: 172.55 best_reward: 577.4000009298325\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 198.45500068068503 average time: 103.0 best_reward: 446.4000023677945\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 246.43500062003733 average time: 147.45 best_reward: 727.7000025808811\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 222.56500062309206 average time: 113.75 best_reward: 447.0000020042062\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 241.3850005246699 average time: 140.55 best_reward: 493.00000124424696\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 259.5150008108467 average time: 133.75 best_reward: 595.5000026449561\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 286.9900007944554 average time: 162.4 best_reward: 575.5000015646219\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 299.51000103354454 average time: 158.5 best_reward: 595.4000020697713\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 380000 / 500000\n",
      "average reward: 309.7150009319186 average time: 168.7 best_reward: 946.2000021189451\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 249.30500072315334 average time: 127.65 best_reward: 447.10000099241734\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 319.81000089384617 average time: 160.65 best_reward: 529.1000009924173\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 236.8750006530434 average time: 114.5 best_reward: 421.4000014439225\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 303.17500095590947 average time: 157.2 best_reward: 727.5000024810433\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 228.20500057302417 average time: 124.75 best_reward: 420.60000175982714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 199.54000043570994 average time: 106.4 best_reward: 419.90000035613775\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 256.79500051550565 average time: 137.2 best_reward: 446.60000079870224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 268.97000084035096 average time: 134.45 best_reward: 577.1000019386411\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 292.680000827834 average time: 150.85 best_reward: 596.2000016570091\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 274.85500090606513 average time: 129.85 best_reward: 730.0000032186508\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 247.7300008662045 average time: 128.75 best_reward: 447.70000122487545\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 190.25000061132013 average time: 99.45 best_reward: 420.4000014811754\n"
     ]
    }
   ],
   "source": [
    "train('./RewardClip', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, reward_clip=15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8170cef7-eefd-4458-aae6-9a27a1fa957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 225.28500018455088 average time: 181.25 best_reward: 593.100001886487\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 215.88000066392124 average time: 126.7 best_reward: 446.60000199079514\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 233.57500073090196 average time: 125.0 best_reward: 447.5000016018748\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 181.0650005944073 average time: 94.05 best_reward: 330.20000080019236\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 264.56000075116754 average time: 158.5 best_reward: 448.1000013202429\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 257.2100008390844 average time: 172.1 best_reward: 595.8000034093857\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 207.0500003129244 average time: 191.0 best_reward: 327.50000131875277\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 80000 / 500000\n",
      "average reward: 269.0500008396804 average time: 171.85 best_reward: 982.5000020340085\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 238.27500047199428 average time: 148.8 best_reward: 492.400001950562\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 295.3150007601827 average time: 246.15 best_reward: 490.4000024795532\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 240.51500060036778 average time: 211.4 best_reward: 419.5000018402934\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 262.1350005019456 average time: 292.0 best_reward: 445.00000025331974\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 279.7550004746765 average time: 242.85 best_reward: 519.1000001579523\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 266.00500058941543 average time: 167.25 best_reward: 492.7000015601516\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 303.77000063322487 average time: 222.05 best_reward: 812.8000021725893\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 233.29500049613415 average time: 137.35 best_reward: 529.4000017791986\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 278.20500052757563 average time: 209.15 best_reward: 811.9000023007393\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 257.1650004737079 average time: 143.75 best_reward: 595.2000013887882\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 358.95000071004034 average time: 206.5 best_reward: 576.3000013306737\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 243.89500057026743 average time: 136.9 best_reward: 446.6000007763505\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 310.90000079236927 average time: 183.75 best_reward: 729.3000023365021\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 235.2900005351752 average time: 127.75 best_reward: 448.5000016018748\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 287.8850005432963 average time: 166.65 best_reward: 527.1000006273389\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 242.50000045970083 average time: 141.5 best_reward: 491.9000011011958\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 210.41500060632825 average time: 108.5 best_reward: 447.9000014513731\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 228.67000054381788 average time: 122.2 best_reward: 420.3000005185604\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 247.03000073842705 average time: 142.55 best_reward: 447.20000257343054\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 272.4700006823987 average time: 134.55 best_reward: 595.2000025510788\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 262.7950007528067 average time: 143.95 best_reward: 421.7000011727214\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 215.9550007082522 average time: 113.25 best_reward: 447.2000017091632\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 197.77500042803587 average time: 103.5 best_reward: 420.60000113397837\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 263.40000072941183 average time: 142.25 best_reward: 729.3000030294061\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 254.22000083886087 average time: 131.0 best_reward: 575.5000026598573\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 278.95500082075597 average time: 162.5 best_reward: 528.9000004529953\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 180.4050005134195 average time: 92.35 best_reward: 328.60000102221966\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 241.53000057935714 average time: 112.2 best_reward: 488.30000069737434\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 211.60000067912043 average time: 116.95 best_reward: 414.70000229775906\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 265.64500086419287 average time: 128.8 best_reward: 493.000002078712\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 279.3150010488927 average time: 152.5 best_reward: 492.6000012755394\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 252.42000095546246 average time: 143.95 best_reward: 727.0000027418137\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 264.8450007442385 average time: 127.95 best_reward: 530.3000024408102\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 236.76500068977475 average time: 113.95 best_reward: 448.4000017121434\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 265.68000098355117 average time: 148.25 best_reward: 421.20000233501196\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 270.9250007446855 average time: 138.6 best_reward: 574.7000017389655\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 273.92000098675487 average time: 141.45 best_reward: 527.1000025123358\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 221.98500075750053 average time: 121.55 best_reward: 419.10000052303076\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 302.63500093854964 average time: 157.65 best_reward: 596.6000017896295\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 250.65500077530743 average time: 135.1 best_reward: 527.7999999672174\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 280.39000094719233 average time: 140.15 best_reward: 526.7000020816922\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 299.62000093087556 average time: 150.0 best_reward: 525.2000017240644\n"
     ]
    }
   ],
   "source": [
    "train('./RewardClip50', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, reward_clip=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd3ce15-d07e-46d6-b5c8-d7df23ccba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 500000\n",
      "average reward: 216.89500045329333 average time: 373.1 best_reward: 485.10000145435333\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 500000\n",
      "average reward: 194.82000031545758 average time: 289.6 best_reward: 408.800000987947\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 500000\n",
      "average reward: 243.49000035077333 average time: 318.4 best_reward: 417.0000014603138\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 500000\n",
      "average reward: 243.58500047884883 average time: 278.25 best_reward: 513.6000009849668\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 500000\n",
      "average reward: 231.68000044412912 average time: 466.3 best_reward: 517.9000019207597\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 500000\n",
      "average reward: 247.3600004773587 average time: 283.15 best_reward: 420.0000015720725\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 500000\n",
      "average reward: 288.28000072091817 average time: 273.3 best_reward: 723.8000030368567\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 500000\n",
      "average reward: 227.7900006208569 average time: 159.35 best_reward: 420.0999998450279\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 500000\n",
      "average reward: 252.79500062689186 average time: 177.8 best_reward: 592.900003388524\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 500000\n",
      "average reward: 207.67500044479965 average time: 137.25 best_reward: 488.90000155568123\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 500000\n",
      "average reward: 217.68000044971706 average time: 109.0 best_reward: 444.6000013798475\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 500000\n",
      "average reward: 286.1650006983429 average time: 158.55 best_reward: 728.6000024229288\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 500000\n",
      "average reward: 225.0200007531792 average time: 134.35 best_reward: 445.90000163018703\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 500000\n",
      "average reward: 172.73500030823052 average time: 96.45 best_reward: 419.3000003695488\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 500000\n",
      "average reward: 208.6950006790459 average time: 117.75 best_reward: 414.9000016152859\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 500000\n",
      "average reward: 214.2950004324317 average time: 117.85 best_reward: 594.7000015601516\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 500000\n",
      "average reward: 251.3300005529076 average time: 136.35 best_reward: 577.6000012308359\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 500000\n",
      "average reward: 233.425000692904 average time: 137.7 best_reward: 575.300001770258\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 500000\n",
      "average reward: 234.43500080630184 average time: 133.65 best_reward: 578.7000024393201\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 500000\n",
      "average reward: 248.4750006072223 average time: 127.9 best_reward: 493.70000284165144\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 500000\n",
      "average reward: 193.85000043287874 average time: 109.8 best_reward: 490.40000189095736\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 500000\n",
      "average reward: 228.47500043921173 average time: 133.45 best_reward: 420.50000147521496\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 500000\n",
      "average reward: 214.78000055365266 average time: 124.25 best_reward: 525.5000028833747\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 500000\n",
      "average reward: 199.38500044718384 average time: 115.55 best_reward: 420.2000015228987\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 500000\n",
      "average reward: 233.29000071920456 average time: 127.8 best_reward: 522.2000025063753\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 500000\n",
      "average reward: 240.55000071674584 average time: 129.1 best_reward: 492.20000110566616\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 500000\n",
      "average reward: 212.56500058434904 average time: 114.85 best_reward: 418.20000091195107\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 500000\n",
      "average reward: 232.98000076785684 average time: 120.7 best_reward: 444.0000011473894\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 500000\n",
      "average reward: 218.33500078432263 average time: 118.0 best_reward: 421.4000017866492\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 500000\n",
      "average reward: 223.65500094741583 average time: 117.0 best_reward: 364.4000016376376\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 500000\n",
      "average reward: 238.11500053070486 average time: 132.65 best_reward: 527.1000020727515\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 500000\n",
      "average reward: 288.4950006756932 average time: 147.6 best_reward: 595.9000013247132\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 500000\n",
      "average reward: 253.6100008264184 average time: 131.1 best_reward: 424.3000017553568\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 500000\n",
      "average reward: 243.45500074438752 average time: 121.95 best_reward: 447.1000021100044\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 500000\n",
      "average reward: 308.56000105887654 average time: 151.8 best_reward: 577.0000021830201\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 500000\n",
      "average reward: 211.7500006765127 average time: 108.75 best_reward: 491.3000018596649\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 500000\n",
      "average reward: 240.07500067837537 average time: 122.55 best_reward: 524.0000019147992\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 500000\n",
      "average reward: 241.45500079877675 average time: 122.05 best_reward: 525.0000021979213\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 500000\n",
      "average reward: 254.19000068232418 average time: 129.0 best_reward: 594.9000022411346\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 500000\n",
      "average reward: 236.54000081941484 average time: 122.0 best_reward: 526.3000020608306\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 500000\n",
      "average reward: 253.46000063307582 average time: 128.5 best_reward: 447.90000109374523\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 500000\n",
      "average reward: 196.56000073924662 average time: 90.5 best_reward: 491.9000019952655\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 500000\n",
      "average reward: 241.0600007984787 average time: 125.75 best_reward: 420.70000230520964\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 500000\n",
      "average reward: 182.55000057928265 average time: 90.2 best_reward: 594.6000018715858\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 500000\n",
      "average reward: 283.45000086613 average time: 146.3 best_reward: 492.30000177770853\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 500000\n",
      "average reward: 232.91000071577727 average time: 119.7 best_reward: 729.2000029161572\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 500000\n",
      "average reward: 200.8850004903972 average time: 101.05 best_reward: 524.4000000879169\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 500000\n",
      "average reward: 246.95000068694353 average time: 126.1 best_reward: 420.3000019043684\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 500000\n",
      "average reward: 267.7200009521097 average time: 147.5 best_reward: 726.2000026926398\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 500000\n",
      "average reward: 269.19500087089835 average time: 135.0 best_reward: 729.100002579391\n"
     ]
    }
   ],
   "source": [
    "train('./RewardClip25', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, reward_clip=25.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1ef32-ae87-4b27-968f-ee69bab5c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up env...\n",
      "Setting up model...\n",
      "Initializing the predictor network\n",
      "Features 512\n",
      "Action Space Discrete(3)\n",
      "Training model...\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 10000 / 10000000\n",
      "average reward: 143.57499794662 average time: 112.75 best_reward: 509.89999236911535\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 20000 / 10000000\n",
      "average reward: 120.70999825634063 average time: 110.45 best_reward: 383.79999401420355\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 30000 / 10000000\n",
      "average reward: 124.26499818488955 average time: 91.75 best_reward: 409.2999930754304\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 40000 / 10000000\n",
      "average reward: 114.07999814637006 average time: 96.75 best_reward: 312.89999459683895\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 50000 / 10000000\n",
      "average reward: 139.384999332577 average time: 81.3 best_reward: 1116.400013588369\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 60000 / 10000000\n",
      "average reward: 136.9049978196621 average time: 63.55 best_reward: 491.79999029636383\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 70000 / 10000000\n",
      "average reward: 112.77499836012721 average time: 56.95 best_reward: 363.6999946385622\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 80000 / 10000000\n",
      "average reward: 155.58999752104282 average time: 71.4 best_reward: 707.9999883770943\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 90000 / 10000000\n",
      "average reward: 125.8449979558587 average time: 54.9 best_reward: 383.2999928370118\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 100000 / 10000000\n",
      "average reward: 148.79499740079046 average time: 57.75 best_reward: 413.99999252706766\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 110000 / 10000000\n",
      "average reward: 132.70499885641038 average time: 73.5 best_reward: 691.6000072136521\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 120000 / 10000000\n",
      "average reward: 149.034997779876 average time: 73.7 best_reward: 420.1999926865101\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 130000 / 10000000\n",
      "average reward: 158.74999721758067 average time: 61.0 best_reward: 577.5999886766076\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 140000 / 10000000\n",
      "average reward: 125.18499796129763 average time: 52.25 best_reward: 440.7999925389886\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 150000 / 10000000\n",
      "average reward: 156.65999754741787 average time: 74.45 best_reward: 425.1999919116497\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 160000 / 10000000\n",
      "average reward: 156.56499751545488 average time: 66.85 best_reward: 396.09999337792397\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 170000 / 10000000\n",
      "average reward: 150.3299974951893 average time: 60.45 best_reward: 415.79999262839556\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 180000 / 10000000\n",
      "average reward: 124.88499801680446 average time: 54.1 best_reward: 294.9999948889017\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 190000 / 10000000\n",
      "average reward: 156.11999743692576 average time: 66.65 best_reward: 335.9999936968088\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 200000 / 10000000\n",
      "average reward: 185.55999888926743 average time: 99.75 best_reward: 1208.9000192210078\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 210000 / 10000000\n",
      "average reward: 194.22999658621848 average time: 79.35 best_reward: 710.3999859690666\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 220000 / 10000000\n",
      "average reward: 128.88499787412584 average time: 52.6 best_reward: 357.99999418854713\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 230000 / 10000000\n",
      "average reward: 176.2649971228093 average time: 69.75 best_reward: 546.2999897003174\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 240000 / 10000000\n",
      "average reward: 173.66499700956047 average time: 74.6 best_reward: 544.5999893471599\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 250000 / 10000000\n",
      "average reward: 164.69999918304384 average time: 91.0 best_reward: 1196.500018723309\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 260000 / 10000000\n",
      "average reward: 117.12499816678465 average time: 58.25 best_reward: 326.59999361634254\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 270000 / 10000000\n",
      "average reward: 137.25999768674373 average time: 59.95 best_reward: 348.8999940007925\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 280000 / 10000000\n",
      "average reward: 192.754998594895 average time: 106.15 best_reward: 1192.3000174090266\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 290000 / 10000000\n",
      "average reward: 130.17499829642475 average time: 59.9 best_reward: 488.000000230968\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 300000 / 10000000\n",
      "average reward: 153.03499836660922 average time: 122.6 best_reward: 688.5000063031912\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 310000 / 10000000\n",
      "average reward: 152.17999748326838 average time: 60.15 best_reward: 362.9999964237213\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 320000 / 10000000\n",
      "average reward: 147.37999758310616 average time: 64.2 best_reward: 324.7999938502908\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 330000 / 10000000\n",
      "average reward: 155.08999747373164 average time: 57.6 best_reward: 363.2999961152673\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 340000 / 10000000\n",
      "average reward: 180.51999682746828 average time: 67.8 best_reward: 587.7999884039164\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 350000 / 10000000\n",
      "average reward: 190.25999751500785 average time: 90.9 best_reward: 668.1000055447221\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 360000 / 10000000\n",
      "average reward: 175.8099970154464 average time: 73.85 best_reward: 556.7999889180064\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 370000 / 10000000\n",
      "average reward: 171.3899970944971 average time: 82.8 best_reward: 525.3999916017056\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 380000 / 10000000\n",
      "average reward: 157.88499732762574 average time: 65.7 best_reward: 383.5999930277467\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 390000 / 10000000\n",
      "average reward: 171.33499721139668 average time: 94.55 best_reward: 403.19999320060015\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 400000 / 10000000\n",
      "average reward: 152.5799978375435 average time: 64.8 best_reward: 468.09999922662973\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 410000 / 10000000\n",
      "average reward: 154.40999741144478 average time: 100.15 best_reward: 595.6999894827604\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 420000 / 10000000\n",
      "average reward: 177.54499702230095 average time: 109.85 best_reward: 453.9999922141433\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 430000 / 10000000\n",
      "average reward: 176.57999755442142 average time: 81.95 best_reward: 597.4000026732683\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 440000 / 10000000\n",
      "average reward: 163.67499750889837 average time: 101.2 best_reward: 467.299999371171\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 450000 / 10000000\n",
      "average reward: 182.0949968881905 average time: 67.05 best_reward: 690.6999864652753\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 460000 / 10000000\n",
      "average reward: 185.39499745368957 average time: 81.4 best_reward: 567.200002707541\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 470000 / 10000000\n",
      "average reward: 214.64499626122415 average time: 77.65 best_reward: 422.0999915897846\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 480000 / 10000000\n",
      "average reward: 182.92499676905572 average time: 62.9 best_reward: 438.69999128580093\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 490000 / 10000000\n",
      "average reward: 251.81499533578753 average time: 86.3 best_reward: 588.7999881505966\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 500000 / 10000000\n",
      "average reward: 194.6899966083467 average time: 128.05 best_reward: 574.5999897941947\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 510000 / 10000000\n",
      "average reward: 222.39499597139655 average time: 80.55 best_reward: 545.2999889627099\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 520000 / 10000000\n",
      "average reward: 236.23499795123934 average time: 127.55 best_reward: 1220.900019980967\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 530000 / 10000000\n",
      "average reward: 150.19999757669865 average time: 61.1 best_reward: 380.79999317228794\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 540000 / 10000000\n",
      "average reward: 187.2449967905879 average time: 66.65 best_reward: 622.6999880746007\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 550000 / 10000000\n",
      "average reward: 209.4249984703958 average time: 107.9 best_reward: 1221.1000205352902\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 560000 / 10000000\n",
      "average reward: 171.48999770358205 average time: 107.95 best_reward: 560.8000015169382\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 570000 / 10000000\n",
      "average reward: 149.13499737530947 average time: 54.3 best_reward: 448.1999914571643\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 580000 / 10000000\n",
      "average reward: 196.16999664865435 average time: 94.75 best_reward: 471.59999287873507\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 590000 / 10000000\n",
      "average reward: 179.96499676443636 average time: 70.55 best_reward: 438.699991106987\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 600000 / 10000000\n",
      "average reward: 244.22999773547053 average time: 141.85 best_reward: 1207.1000180840492\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 610000 / 10000000\n",
      "average reward: 177.8299983367324 average time: 109.2 best_reward: 957.0000101029873\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 620000 / 10000000\n",
      "average reward: 310.089996381104 average time: 174.6 best_reward: 1208.4000195115805\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 630000 / 10000000\n",
      "average reward: 246.79999838471412 average time: 172.65 best_reward: 1306.8000231161714\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 640000 / 10000000\n",
      "average reward: 185.19499708898365 average time: 71.75 best_reward: 552.6999895200133\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 650000 / 10000000\n",
      "average reward: 229.26999675892293 average time: 200.65 best_reward: 565.4000032097101\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 660000 / 10000000\n",
      "average reward: 200.4899964157492 average time: 115.95 best_reward: 527.0999908298254\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 670000 / 10000000\n",
      "average reward: 256.0849979098886 average time: 115.2 best_reward: 1370.7000273391604\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 680000 / 10000000\n",
      "average reward: 272.63499716483057 average time: 129.65 best_reward: 1219.4000202789903\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 690000 / 10000000\n",
      "average reward: 175.9049970444292 average time: 95.2 best_reward: 381.0999923273921\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 700000 / 10000000\n",
      "average reward: 207.709996182099 average time: 73.4 best_reward: 492.999990850687\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 710000 / 10000000\n",
      "average reward: 235.46499581523238 average time: 87.8 best_reward: 422.7999916896224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 720000 / 10000000\n",
      "average reward: 239.70499560758472 average time: 94.05 best_reward: 577.5999883189797\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 730000 / 10000000\n",
      "average reward: 233.79999815262855 average time: 152.7 best_reward: 1309.8000238388777\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 740000 / 10000000\n",
      "average reward: 276.02499661780894 average time: 125.5 best_reward: 1047.4000143185258\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 750000 / 10000000\n",
      "average reward: 277.4499972190708 average time: 134.6 best_reward: 1296.800023637712\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 760000 / 10000000\n",
      "average reward: 262.70999541096387 average time: 149.35 best_reward: 492.9999904483557\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 770000 / 10000000\n",
      "average reward: 323.4949960913509 average time: 136.35 best_reward: 1260.6000217273831\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 780000 / 10000000\n",
      "average reward: 168.41999705545604 average time: 63.05 best_reward: 329.09999376535416\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 790000 / 10000000\n",
      "average reward: 273.08999742157755 average time: 166.7 best_reward: 1332.1000239998102\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 800000 / 10000000\n",
      "average reward: 163.6799971178174 average time: 60.2 best_reward: 391.79999493062496\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 810000 / 10000000\n",
      "average reward: 249.5249953892082 average time: 85.6 best_reward: 473.0999907106161\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 820000 / 10000000\n",
      "average reward: 266.59499848634005 average time: 149.7 best_reward: 1323.200024470687\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 830000 / 10000000\n",
      "average reward: 287.52499694600704 average time: 171.4 best_reward: 1208.4000197276473\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 840000 / 10000000\n",
      "average reward: 357.0399998057634 average time: 222.55 best_reward: 1281.700021609664\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 850000 / 10000000\n",
      "average reward: 274.7999948170036 average time: 103.8 best_reward: 711.099986590445\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 860000 / 10000000\n",
      "average reward: 189.13999660387634 average time: 68.5 best_reward: 447.5999914929271\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 870000 / 10000000\n",
      "average reward: 233.02999719418585 average time: 124.65 best_reward: 821.6000110805035\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 880000 / 10000000\n",
      "average reward: 343.93999851159754 average time: 180.85 best_reward: 1299.0000221803784\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 890000 / 10000000\n",
      "average reward: 239.50999550707638 average time: 81.2 best_reward: 611.6999878063798\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 900000 / 10000000\n",
      "average reward: 203.54499628171325 average time: 73.7 best_reward: 592.3999888077378\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 910000 / 10000000\n",
      "average reward: 211.7949969675392 average time: 91.25 best_reward: 622.4999876618385\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 920000 / 10000000\n",
      "average reward: 203.52499616257847 average time: 69.95 best_reward: 511.79998933523893\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 930000 / 10000000\n",
      "average reward: 171.979996862635 average time: 58.5 best_reward: 595.0999876484275\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 940000 / 10000000\n",
      "average reward: 178.72999687604607 average time: 67.1 best_reward: 611.4999877512455\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 950000 / 10000000\n",
      "average reward: 216.50499597042798 average time: 73.4 best_reward: 492.59999039024115\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 960000 / 10000000\n",
      "average reward: 166.69999708421528 average time: 66.6 best_reward: 552.2999894544482\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 970000 / 10000000\n",
      "average reward: 188.95499691292645 average time: 85.05 best_reward: 404.7999926581979\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 980000 / 10000000\n",
      "average reward: 270.2849971063435 average time: 127.85 best_reward: 1210.500018812716\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 990000 / 10000000\n",
      "average reward: 264.35999694131317 average time: 131.45 best_reward: 1108.0000152364373\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1000000 / 10000000\n",
      "average reward: 164.2699970677495 average time: 58.05 best_reward: 610.5999881699681\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1010000 / 10000000\n",
      "average reward: 221.82499586120247 average time: 74.3 best_reward: 859.5999824926257\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1020000 / 10000000\n",
      "average reward: 335.01999605223534 average time: 140.95 best_reward: 1312.80002322793\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1030000 / 10000000\n",
      "average reward: 227.1499972231686 average time: 127.7 best_reward: 681.5999882519245\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1040000 / 10000000\n",
      "average reward: 268.7399949710816 average time: 105.85 best_reward: 726.4999860823154\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1050000 / 10000000\n",
      "average reward: 211.6749966353178 average time: 76.6 best_reward: 589.8999887704849\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1060000 / 10000000\n",
      "average reward: 192.83999647572637 average time: 115.95 best_reward: 512.4999902695417\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1070000 / 10000000\n",
      "average reward: 278.13499801680445 average time: 139.45 best_reward: 1329.2000233903527\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1080000 / 10000000\n",
      "average reward: 221.12999587506056 average time: 74.5 best_reward: 405.09999211877584\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1090000 / 10000000\n",
      "average reward: 274.92999497912825 average time: 147.95 best_reward: 816.2999848052859\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1100000 / 10000000\n",
      "average reward: 251.72999532558023 average time: 89.7 best_reward: 775.5999851375818\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1110000 / 10000000\n",
      "average reward: 241.2599979698658 average time: 133.6 best_reward: 1091.0000160485506\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1120000 / 10000000\n",
      "average reward: 246.85499540939927 average time: 82.1 best_reward: 801.2999854758382\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1130000 / 10000000\n",
      "average reward: 302.04499417878685 average time: 149.05 best_reward: 1038.699979007244\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1140000 / 10000000\n",
      "average reward: 187.70499645732343 average time: 103.0 best_reward: 347.49999302625656\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1150000 / 10000000\n",
      "average reward: 235.50499560907483 average time: 85.4 best_reward: 529.5999894961715\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1160000 / 10000000\n",
      "average reward: 208.9199961349368 average time: 78.5 best_reward: 622.9999876320362\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1170000 / 10000000\n",
      "average reward: 299.3249945171177 average time: 116.85 best_reward: 859.8999829664826\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1180000 / 10000000\n",
      "average reward: 259.63499577119944 average time: 136.65 best_reward: 588.2999881803989\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1190000 / 10000000\n",
      "average reward: 206.31499640531837 average time: 77.2 best_reward: 772.6999853551388\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1200000 / 10000000\n",
      "average reward: 244.03499558269976 average time: 88.3 best_reward: 611.0999879464507\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1210000 / 10000000\n",
      "average reward: 151.43499787412583 average time: 57.0 best_reward: 489.40000000596046\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1220000 / 10000000\n",
      "average reward: 234.69999576881528 average time: 130.9 best_reward: 611.4999887272716\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1230000 / 10000000\n",
      "average reward: 218.80499609708787 average time: 86.4 best_reward: 710.5999862700701\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1240000 / 10000000\n",
      "average reward: 278.2999954331666 average time: 113.15 best_reward: 588.6999885812402\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1250000 / 10000000\n",
      "average reward: 181.81999676339328 average time: 65.7 best_reward: 404.59999211877584\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1260000 / 10000000\n",
      "average reward: 244.5699955366552 average time: 127.5 best_reward: 710.8999862149358\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1270000 / 10000000\n",
      "average reward: 206.95499632880092 average time: 78.85 best_reward: 525.9999901950359\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1280000 / 10000000\n",
      "average reward: 241.6499956626445 average time: 90.8 best_reward: 415.7999919876456\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1290000 / 10000000\n",
      "average reward: 235.48499573320152 average time: 78.35 best_reward: 589.1999885067344\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1300000 / 10000000\n",
      "average reward: 252.70499681532382 average time: 120.1 best_reward: 854.1000107899308\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1310000 / 10000000\n",
      "average reward: 359.7099944926798 average time: 174.25 best_reward: 983.6999815255404\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1320000 / 10000000\n",
      "average reward: 286.514994617179 average time: 92.7 best_reward: 801.0999838709831\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1330000 / 10000000\n",
      "average reward: 186.26499667204916 average time: 115.7 best_reward: 588.3999884203076\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1340000 / 10000000\n",
      "average reward: 208.5949961911887 average time: 73.0 best_reward: 1114.0999779105186\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1350000 / 10000000\n",
      "average reward: 226.63499581217766 average time: 75.75 best_reward: 605.6999877914786\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1360000 / 10000000\n",
      "average reward: 247.49499573372304 average time: 90.7 best_reward: 771.5999846458435\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1370000 / 10000000\n",
      "average reward: 190.79999658465385 average time: 72.2 best_reward: 449.6999916881323\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1380000 / 10000000\n",
      "average reward: 246.0799956291914 average time: 90.75 best_reward: 611.8999885544181\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1390000 / 10000000\n",
      "average reward: 273.62499730847776 average time: 176.3 best_reward: 1246.1000210940838\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1400000 / 10000000\n",
      "average reward: 215.42499676607548 average time: 118.5 best_reward: 609.0000034421682\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1410000 / 10000000\n",
      "average reward: 234.68999573774636 average time: 93.55 best_reward: 1039.9999803677201\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1420000 / 10000000\n",
      "average reward: 291.20499491877854 average time: 108.9 best_reward: 799.8999839499593\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1430000 / 10000000\n",
      "average reward: 271.3149949207902 average time: 92.35 best_reward: 860.3999828100204\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1440000 / 10000000\n",
      "average reward: 208.69999620765446 average time: 75.65 best_reward: 492.7999901995063\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1450000 / 10000000\n",
      "average reward: 209.28499624691904 average time: 71.35 best_reward: 571.299988925457\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1460000 / 10000000\n",
      "average reward: 192.90499666593968 average time: 72.25 best_reward: 449.6999914422631\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1470000 / 10000000\n",
      "average reward: 215.55499612279237 average time: 70.3 best_reward: 1039.3999796062708\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1480000 / 10000000\n",
      "average reward: 270.669995027408 average time: 141.3 best_reward: 549.3999888896942\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1490000 / 10000000\n",
      "average reward: 265.28999515995383 average time: 95.95 best_reward: 586.899989053607\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1500000 / 10000000\n",
      "average reward: 278.8349958144128 average time: 118.6 best_reward: 632.6999884024262\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1510000 / 10000000\n",
      "average reward: 292.15999696701766 average time: 139.5 best_reward: 1282.5000210180879\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1520000 / 10000000\n",
      "average reward: 303.8249942909926 average time: 111.2 best_reward: 802.499984242022\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1530000 / 10000000\n",
      "average reward: 258.17499546036123 average time: 94.8 best_reward: 450.09999153018\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1540000 / 10000000\n",
      "average reward: 281.4799951374531 average time: 119.75 best_reward: 666.3999879360199\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1550000 / 10000000\n",
      "average reward: 199.87499681860209 average time: 129.65 best_reward: 729.5999865308404\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1560000 / 10000000\n",
      "average reward: 286.09999457784 average time: 171.95 best_reward: 839.2999829649925\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1570000 / 10000000\n",
      "average reward: 325.284993923828 average time: 112.85 best_reward: 730.0999857336283\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1580000 / 10000000\n",
      "average reward: 333.7049946643412 average time: 119.8 best_reward: 1115.7999793812633\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1590000 / 10000000\n",
      "average reward: 316.8799945995212 average time: 191.6 best_reward: 696.1999859511852\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1600000 / 10000000\n",
      "average reward: 274.0999966252595 average time: 166.85 best_reward: 666.7000047490001\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1610000 / 10000000\n",
      "average reward: 279.59999564290047 average time: 178.9 best_reward: 793.2999842464924\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1620000 / 10000000\n",
      "average reward: 279.754995309189 average time: 114.2 best_reward: 731.8999852910638\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 1630000 / 10000000\n",
      "average reward: 367.5499933350831 average time: 148.25 best_reward: 1116.5999801009893\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1640000 / 10000000\n",
      "average reward: 293.599994777143 average time: 115.6 best_reward: 891.3999835625291\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1650000 / 10000000\n",
      "average reward: 202.10999639220535 average time: 85.4 best_reward: 802.5999839901924\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1660000 / 10000000\n",
      "average reward: 207.0499964427203 average time: 123.0 best_reward: 692.199985794723\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1670000 / 10000000\n",
      "average reward: 318.0949939642102 average time: 167.85 best_reward: 973.8999811336398\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1680000 / 10000000\n",
      "average reward: 303.9599943988025 average time: 151.0 best_reward: 800.599983908236\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1690000 / 10000000\n",
      "average reward: 305.38999510370195 average time: 166.5 best_reward: 840.9999827370048\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1700000 / 10000000\n",
      "average reward: 209.88999619968234 average time: 181.65 best_reward: 557.7999888211489\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1710000 / 10000000\n",
      "average reward: 235.58999618627132 average time: 90.9 best_reward: 792.5999847352505\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1720000 / 10000000\n",
      "average reward: 294.6699954509735 average time: 126.35 best_reward: 716.899986423552\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1730000 / 10000000\n",
      "average reward: 318.23499426208434 average time: 115.8 best_reward: 830.1999844685197\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1740000 / 10000000\n",
      "average reward: 275.0649955846369 average time: 106.35 best_reward: 674.299987025559\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1750000 / 10000000\n",
      "average reward: 351.6649937842041 average time: 138.35 best_reward: 1144.0999763086438\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1760000 / 10000000\n",
      "average reward: 315.0299949705601 average time: 122.85 best_reward: 829.6999838426709\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1770000 / 10000000\n",
      "average reward: 266.47499507442114 average time: 137.9 best_reward: 828.5999834463\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1780000 / 10000000\n",
      "average reward: 270.3899949308485 average time: 96.95 best_reward: 425.6999918371439\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1790000 / 10000000\n",
      "average reward: 350.02999375388026 average time: 176.3 best_reward: 1079.2999792322516\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1800000 / 10000000\n",
      "average reward: 232.8049960758537 average time: 89.35 best_reward: 767.4999849200249\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1810000 / 10000000\n",
      "average reward: 226.16999592892824 average time: 127.1 best_reward: 550.8999889716506\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1820000 / 10000000\n",
      "average reward: 340.59999378211796 average time: 117.0 best_reward: 973.5999813228846\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1830000 / 10000000\n",
      "average reward: 288.80999458990993 average time: 96.0 best_reward: 792.7999853491783\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1840000 / 10000000\n",
      "average reward: 222.01499597989022 average time: 122.9 best_reward: 785.4999855086207\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1850000 / 10000000\n",
      "average reward: 244.66499601602555 average time: 99.9 best_reward: 815.9999843835831\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1860000 / 10000000\n",
      "average reward: 303.82999441325666 average time: 146.25 best_reward: 1039.6999819651246\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1870000 / 10000000\n",
      "average reward: 280.66499489173293 average time: 100.05 best_reward: 1040.2999799475074\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1880000 / 10000000\n",
      "average reward: 237.43999566547572 average time: 80.0 best_reward: 793.4999857991934\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1890000 / 10000000\n",
      "average reward: 235.28999565429984 average time: 86.4 best_reward: 526.9999899938703\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1900000 / 10000000\n",
      "average reward: 328.7949948251247 average time: 133.6 best_reward: 835.1999839320779\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1910000 / 10000000\n",
      "average reward: 267.28999518379567 average time: 141.4 best_reward: 1040.0999818071723\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1920000 / 10000000\n",
      "average reward: 279.2349961709231 average time: 152.1 best_reward: 792.3999840989709\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1930000 / 10000000\n",
      "average reward: 251.1099963914603 average time: 154.6 best_reward: 518.6999962553382\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1940000 / 10000000\n",
      "average reward: 250.42499681599438 average time: 127.35 best_reward: 900.7000093236566\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1950000 / 10000000\n",
      "average reward: 272.84499485008416 average time: 89.65 best_reward: 712.59998575598\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 1960000 / 10000000\n",
      "average reward: 260.5549950398505 average time: 85.1 best_reward: 655.8999869301915\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1970000 / 10000000\n",
      "average reward: 283.42499482855203 average time: 125.75 best_reward: 1029.0999800264835\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1980000 / 10000000\n",
      "average reward: 389.4049949910492 average time: 157.55 best_reward: 1272.7000222206116\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 1990000 / 10000000\n",
      "average reward: 392.83499301970005 average time: 141.7 best_reward: 991.1999811306596\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2000000 / 10000000\n",
      "average reward: 304.6999943390489 average time: 146.5 best_reward: 620.9999875351787\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 2010000 / 10000000\n",
      "average reward: 440.05499593652786 average time: 223.25 best_reward: 1312.3000223711133\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2020000 / 10000000\n",
      "average reward: 278.2299948383123 average time: 94.65 best_reward: 539.199988745153\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2030000 / 10000000\n",
      "average reward: 231.78999579884112 average time: 84.4 best_reward: 644.599987372756\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2040000 / 10000000\n",
      "average reward: 345.974996028468 average time: 175.7 best_reward: 1318.7000231444836\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2050000 / 10000000\n",
      "average reward: 450.6399988669902 average time: 273.55 best_reward: 1347.0000246241689\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2060000 / 10000000\n",
      "average reward: 417.0799948241562 average time: 253.25 best_reward: 1229.2000209540129\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2070000 / 10000000\n",
      "average reward: 244.85999545715748 average time: 85.9 best_reward: 730.4999858289957\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2080000 / 10000000\n",
      "average reward: 262.24499508664013 average time: 90.1 best_reward: 1036.9999795630574\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2090000 / 10000000\n",
      "average reward: 382.5849978834391 average time: 183.7 best_reward: 1353.100025638938\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2100000 / 10000000\n",
      "average reward: 221.54999617300928 average time: 81.55 best_reward: 611.1999878138304\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2110000 / 10000000\n",
      "average reward: 240.55999594405293 average time: 81.9 best_reward: 529.8999900445342\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2120000 / 10000000\n",
      "average reward: 209.569996625185 average time: 80.9 best_reward: 487.1000001206994\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2130000 / 10000000\n",
      "average reward: 277.27999480739237 average time: 91.0 best_reward: 972.3999803811312\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2140000 / 10000000\n",
      "average reward: 285.144996194914 average time: 174.55 best_reward: 984.8999847173691\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2150000 / 10000000\n",
      "average reward: 317.4149940118194 average time: 105.25 best_reward: 1066.7999787926674\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2160000 / 10000000\n",
      "average reward: 174.35999689027668 average time: 61.9 best_reward: 510.9999908134341\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2170000 / 10000000\n",
      "average reward: 361.9999943010509 average time: 143.3 best_reward: 986.2999823391438\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2180000 / 10000000\n",
      "average reward: 321.4999940756708 average time: 121.4 best_reward: 831.0999848544598\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2190000 / 10000000\n",
      "average reward: 324.8899942852557 average time: 115.4 best_reward: 1070.7999797537923\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2200000 / 10000000\n",
      "average reward: 393.95499747358264 average time: 259.3 best_reward: 1116.1000166013837\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2210000 / 10000000\n",
      "average reward: 182.1649967804551 average time: 79.0 best_reward: 765.8999848663807\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2220000 / 10000000\n",
      "average reward: 223.70999589934945 average time: 76.1 best_reward: 730.6999863758683\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2230000 / 10000000\n",
      "average reward: 211.17999707311392 average time: 83.55 best_reward: 668.2000054493546\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2240000 / 10000000\n",
      "average reward: 240.91499550752343 average time: 88.35 best_reward: 729.8999856188893\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2250000 / 10000000\n",
      "average reward: 306.6749949194491 average time: 114.75 best_reward: 729.9999855086207\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 2260000 / 10000000\n",
      "average reward: 336.67499336004255 average time: 153.55 best_reward: 1117.0999766141176\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2270000 / 10000000\n",
      "average reward: 326.08499391451477 average time: 156.35 best_reward: 1116.1999773606658\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2280000 / 10000000\n",
      "average reward: 313.83999538831415 average time: 132.05 best_reward: 729.4999853819609\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2290000 / 10000000\n",
      "average reward: 290.79999460242686 average time: 148.15 best_reward: 729.999986641109\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2300000 / 10000000\n",
      "average reward: 294.56499455682933 average time: 110.8 best_reward: 623.9999881833792\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2310000 / 10000000\n",
      "average reward: 337.3049934547395 average time: 185.3 best_reward: 1117.0999765694141\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 2320000 / 10000000\n",
      "average reward: 297.43499456718564 average time: 159.5 best_reward: 1116.6999775767326\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2330000 / 10000000\n",
      "average reward: 354.07499328106644 average time: 169.5 best_reward: 741.799986474216\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2340000 / 10000000\n",
      "average reward: 330.3799941968173 average time: 208.15 best_reward: 1117.0999771282077\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2350000 / 10000000\n",
      "average reward: 247.47999563142656 average time: 135.85 best_reward: 690.499987103045\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2360000 / 10000000\n",
      "average reward: 326.1449957240373 average time: 136.0 best_reward: 965.2000147998333\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2370000 / 10000000\n",
      "average reward: 285.79999499432745 average time: 108.2 best_reward: 1116.0999798178673\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2380000 / 10000000\n",
      "average reward: 257.68999641761184 average time: 121.9 best_reward: 986.1999850422144\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2390000 / 10000000\n",
      "average reward: 326.5999962247908 average time: 162.25 best_reward: 1203.2000194489956\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2400000 / 10000000\n",
      "average reward: 314.459994494915 average time: 174.7 best_reward: 983.8999820351601\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2410000 / 10000000\n",
      "average reward: 246.34999569505453 average time: 107.25 best_reward: 823.1999861672521\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2420000 / 10000000\n",
      "average reward: 237.66999588049947 average time: 93.6 best_reward: 624.8999871611595\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2430000 / 10000000\n",
      "average reward: 355.1549963612109 average time: 159.65 best_reward: 1353.0000258386135\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2440000 / 10000000\n",
      "average reward: 262.3349974025041 average time: 122.6 best_reward: 1222.4000196009874\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2450000 / 10000000\n",
      "average reward: 286.6999956212938 average time: 109.25 best_reward: 1054.7999841943383\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2460000 / 10000000\n",
      "average reward: 249.96999585181476 average time: 115.85 best_reward: 467.6999915763736\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2470000 / 10000000\n",
      "average reward: 283.1349950812757 average time: 102.6 best_reward: 794.9999859184027\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2480000 / 10000000\n",
      "average reward: 223.7799975387752 average time: 98.5 best_reward: 728.799987539649\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2490000 / 10000000\n",
      "average reward: 263.8599958091974 average time: 103.8 best_reward: 642.8999908715487\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2500000 / 10000000\n",
      "average reward: 242.6449960116297 average time: 124.0 best_reward: 643.6999888196588\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2510000 / 10000000\n",
      "average reward: 233.84499664716424 average time: 92.5 best_reward: 1115.1999825686216\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2520000 / 10000000\n",
      "average reward: 296.9199959717691 average time: 118.15 best_reward: 717.0999868437648\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2530000 / 10000000\n",
      "average reward: 186.47999711744487 average time: 77.0 best_reward: 652.9999877884984\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2540000 / 10000000\n",
      "average reward: 281.86999784596264 average time: 216.4 best_reward: 1286.8000208958983\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2550000 / 10000000\n",
      "average reward: 331.51999802924695 average time: 187.7 best_reward: 1368.1000260934234\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2560000 / 10000000\n",
      "average reward: 288.7999977890402 average time: 153.55 best_reward: 1221.3000213429332\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2570000 / 10000000\n",
      "average reward: 301.03499557338654 average time: 111.45 best_reward: 733.0999883040786\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2580000 / 10000000\n",
      "average reward: 324.6799992728978 average time: 178.55 best_reward: 1306.4000226333737\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2590000 / 10000000\n",
      "average reward: 251.00999600552024 average time: 105.6 best_reward: 611.6999892368913\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2600000 / 10000000\n",
      "average reward: 208.42499719038605 average time: 95.25 best_reward: 403.2999946549535\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2610000 / 10000000\n",
      "average reward: 348.3749972049147 average time: 168.35 best_reward: 1370.7000261098146\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2620000 / 10000000\n",
      "average reward: 208.59499720260501 average time: 89.7 best_reward: 446.99999506026506\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2630000 / 10000000\n",
      "average reward: 203.73499752916396 average time: 82.5 best_reward: 565.6000029593706\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2640000 / 10000000\n",
      "average reward: 273.8999959688634 average time: 105.1 best_reward: 722.9999885708094\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2650000 / 10000000\n",
      "average reward: 204.25499781034887 average time: 124.05 best_reward: 660.5000052005053\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2660000 / 10000000\n",
      "average reward: 240.5999966133386 average time: 124.25 best_reward: 873.9999881759286\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2670000 / 10000000\n",
      "average reward: 190.0299971383065 average time: 112.2 best_reward: 545.299990221858\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2680000 / 10000000\n",
      "average reward: 191.71499758921564 average time: 103.05 best_reward: 360.8999937772751\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2690000 / 10000000\n",
      "average reward: 380.7049987036735 average time: 202.1 best_reward: 1347.800024278462\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2700000 / 10000000\n",
      "average reward: 343.7049971975386 average time: 152.6 best_reward: 1318.1000263169408\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2710000 / 10000000\n",
      "average reward: 245.30999648235738 average time: 142.9 best_reward: 743.1999910920858\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2720000 / 10000000\n",
      "average reward: 197.53999753445387 average time: 82.55 best_reward: 498.79999931901693\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2730000 / 10000000\n",
      "average reward: 208.09999699182808 average time: 97.5 best_reward: 527.499990798533\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2740000 / 10000000\n",
      "average reward: 339.8649994418025 average time: 250.95 best_reward: 1352.4000245183706\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2750000 / 10000000\n",
      "average reward: 317.11999953947964 average time: 172.85 best_reward: 1315.5000222548842\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2760000 / 10000000\n",
      "average reward: 246.3949989091605 average time: 111.85 best_reward: 1373.600026063621\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2770000 / 10000000\n",
      "average reward: 210.06999709792436 average time: 139.8 best_reward: 619.3999916687608\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2780000 / 10000000\n",
      "average reward: 209.29999813623726 average time: 107.75 best_reward: 666.2000062316656\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2790000 / 10000000\n",
      "average reward: 235.74499632939697 average time: 138.65 best_reward: 689.5999888256192\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2800000 / 10000000\n",
      "average reward: 236.2999963440001 average time: 83.0 best_reward: 551.1999899744987\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2810000 / 10000000\n",
      "average reward: 219.2299968432635 average time: 110.5 best_reward: 628.1999899148941\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2820000 / 10000000\n",
      "average reward: 161.82499798201025 average time: 103.25 best_reward: 463.59999945759773\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2830000 / 10000000\n",
      "average reward: 236.8049965158105 average time: 91.9 best_reward: 827.7999860569835\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2840000 / 10000000\n",
      "average reward: 240.55999660678208 average time: 135.55 best_reward: 795.1999885067344\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2850000 / 10000000\n",
      "average reward: 235.70499637909234 average time: 142.3 best_reward: 638.5999893546104\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2860000 / 10000000\n",
      "average reward: 223.73499670550228 average time: 79.65 best_reward: 641.799990914762\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2870000 / 10000000\n",
      "average reward: 185.84999720528722 average time: 65.8 best_reward: 428.99999257177114\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2880000 / 10000000\n",
      "average reward: 242.5549989234656 average time: 114.1 best_reward: 1344.6000259071589\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 2890000 / 10000000\n",
      "average reward: 302.3949954278767 average time: 110.05 best_reward: 985.9999836757779\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2900000 / 10000000\n",
      "average reward: 172.77999740056694 average time: 67.7 best_reward: 421.49999207258224\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2910000 / 10000000\n",
      "average reward: 304.9199983306229 average time: 179.0 best_reward: 1377.40002733469\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2920000 / 10000000\n",
      "average reward: 283.42499778047204 average time: 130.0 best_reward: 1354.6000266224146\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2930000 / 10000000\n",
      "average reward: 279.05999834910034 average time: 176.65 best_reward: 1345.7000256925821\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2940000 / 10000000\n",
      "average reward: 268.64999842569233 average time: 129.9 best_reward: 1225.1000235676765\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2950000 / 10000000\n",
      "average reward: 223.50499925427138 average time: 109.25 best_reward: 1382.400028347969\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2960000 / 10000000\n",
      "average reward: 284.6850005399436 average time: 155.3 best_reward: 1407.4000296890736\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2970000 / 10000000\n",
      "average reward: 231.76999648436905 average time: 84.7 best_reward: 727.999989002943\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2980000 / 10000000\n",
      "average reward: 298.9149972114712 average time: 133.75 best_reward: 965.6000175029039\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 2990000 / 10000000\n",
      "average reward: 291.79000000841916 average time: 169.25 best_reward: 1317.8000245168805\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3000000 / 10000000\n",
      "average reward: 323.1549997787923 average time: 189.05 best_reward: 1314.700023598969\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3010000 / 10000000\n",
      "average reward: 261.62499859556556 average time: 132.85 best_reward: 1371.9000261127949\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3020000 / 10000000\n",
      "average reward: 502.0949996624142 average time: 278.65 best_reward: 1382.2000268995762\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3030000 / 10000000\n",
      "average reward: 203.71499676965178 average time: 75.85 best_reward: 614.7999898791313\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3040000 / 10000000\n",
      "average reward: 324.8299978084862 average time: 148.1 best_reward: 1361.7000254541636\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3050000 / 10000000\n",
      "average reward: 209.57999662086368 average time: 69.15 best_reward: 1117.2999789640307\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3060000 / 10000000\n",
      "average reward: 431.26499827429654 average time: 218.15 best_reward: 1421.1000292673707\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3070000 / 10000000\n",
      "average reward: 224.78499659523368 average time: 126.5 best_reward: 611.0999913066626\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3080000 / 10000000\n",
      "average reward: 254.7749985933304 average time: 137.5 best_reward: 1399.5000279471278\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3090000 / 10000000\n",
      "average reward: 274.4199984759092 average time: 173.85 best_reward: 1405.200029052794\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3100000 / 10000000\n",
      "average reward: 233.94499901980163 average time: 106.75 best_reward: 1507.4000259637833\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3110000 / 10000000\n",
      "average reward: 157.0249977722764 average time: 57.75 best_reward: 588.0999919250607\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3120000 / 10000000\n",
      "average reward: 147.29999823085964 average time: 57.65 best_reward: 551.299992673099\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3130000 / 10000000\n",
      "average reward: 287.1349957205355 average time: 108.1 best_reward: 718.6999875083566\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3140000 / 10000000\n",
      "average reward: 282.11499839015306 average time: 130.05 best_reward: 1387.2000276744366\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3150000 / 10000000\n",
      "average reward: 233.33999697342514 average time: 78.8 best_reward: 985.8999892994761\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3160000 / 10000000\n",
      "average reward: 192.74499745368956 average time: 71.8 best_reward: 622.9999913200736\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3170000 / 10000000\n",
      "average reward: 229.79499642588198 average time: 87.45 best_reward: 662.5999891683459\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3180000 / 10000000\n",
      "average reward: 262.2949986808002 average time: 123.1 best_reward: 1354.2000262364745\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3190000 / 10000000\n",
      "average reward: 326.24999573789535 average time: 131.0 best_reward: 985.3999861478806\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3200000 / 10000000\n",
      "average reward: 173.81499754413963 average time: 121.4 best_reward: 467.39999160170555\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3210000 / 10000000\n",
      "average reward: 340.93999680392443 average time: 158.4 best_reward: 986.699985973537\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3220000 / 10000000\n",
      "average reward: 193.61999739855528 average time: 90.2 best_reward: 469.0999910533428\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3230000 / 10000000\n",
      "average reward: 217.8799967382103 average time: 169.2 best_reward: 588.6999910026789\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3240000 / 10000000\n",
      "average reward: 314.3949951957911 average time: 111.5 best_reward: 792.9999872744083\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3250000 / 10000000\n",
      "average reward: 207.25999701544643 average time: 76.4 best_reward: 662.8999880999327\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3260000 / 10000000\n",
      "average reward: 282.5449957743287 average time: 111.05 best_reward: 560.9999922290444\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3270000 / 10000000\n",
      "average reward: 253.73499635495244 average time: 140.35 best_reward: 690.0999896302819\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3280000 / 10000000\n",
      "average reward: 297.15999839119615 average time: 186.4 best_reward: 1032.2000173032284\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3290000 / 10000000\n",
      "average reward: 333.6499972485006 average time: 146.0 best_reward: 1364.6000279784203\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3300000 / 10000000\n",
      "average reward: 175.34999796040356 average time: 66.6 best_reward: 588.3999912962317\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3310000 / 10000000\n",
      "average reward: 244.95499642454087 average time: 101.05 best_reward: 815.3999913930893\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3320000 / 10000000\n",
      "average reward: 376.0149964444339 average time: 153.35 best_reward: 1399.0000282227993\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3330000 / 10000000\n",
      "average reward: 250.9749966096133 average time: 93.9 best_reward: 695.2999906688929\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3340000 / 10000000\n",
      "average reward: 262.72999661415815 average time: 104.05 best_reward: 784.1999880895019\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3350000 / 10000000\n",
      "average reward: 291.1749976813793 average time: 124.65 best_reward: 1207.9000167995691\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3360000 / 10000000\n",
      "average reward: 148.53999823629857 average time: 62.25 best_reward: 298.69999530911446\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3370000 / 10000000\n",
      "average reward: 209.48999717831612 average time: 104.7 best_reward: 424.6999938711524\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3380000 / 10000000\n",
      "average reward: 224.6749966453761 average time: 85.45 best_reward: 971.4999827668071\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3390000 / 10000000\n",
      "average reward: 286.8049959119409 average time: 116.95 best_reward: 800.3999851569533\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3400000 / 10000000\n",
      "average reward: 276.84499596133827 average time: 98.2 best_reward: 730.2999905794859\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3410000 / 10000000\n",
      "average reward: 196.9899970255792 average time: 66.55 best_reward: 382.29999446868896\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3420000 / 10000000\n",
      "average reward: 202.5599971216172 average time: 140.6 best_reward: 529.4999928697944\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3430000 / 10000000\n",
      "average reward: 297.45499691553414 average time: 200.0 best_reward: 1051.9000144004822\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3440000 / 10000000\n",
      "average reward: 313.6549973141402 average time: 136.7 best_reward: 1266.900021880865\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3450000 / 10000000\n",
      "average reward: 312.96999539770184 average time: 173.75 best_reward: 770.1999867931008\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3460000 / 10000000\n",
      "average reward: 287.28499831184746 average time: 130.2 best_reward: 1379.4000279456377\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3470000 / 10000000\n",
      "average reward: 217.03999713100492 average time: 99.3 best_reward: 746.7999902665615\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3480000 / 10000000\n",
      "average reward: 316.23999493308366 average time: 160.3 best_reward: 842.2999848723412\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3490000 / 10000000\n",
      "average reward: 244.539998319 average time: 116.85 best_reward: 1229.4000211656094\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3500000 / 10000000\n",
      "average reward: 217.39999929368497 average time: 116.85 best_reward: 1248.9000210091472\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3510000 / 10000000\n",
      "average reward: 204.22999760732054 average time: 102.0 best_reward: 724.6999934539199\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3520000 / 10000000\n",
      "average reward: 219.0799969471991 average time: 80.0 best_reward: 482.3999925777316\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3530000 / 10000000\n",
      "average reward: 161.4699976786971 average time: 57.45 best_reward: 593.3999896273017\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3540000 / 10000000\n",
      "average reward: 182.3899979431182 average time: 134.7 best_reward: 619.4999918341637\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3550000 / 10000000\n",
      "average reward: 201.2049973014742 average time: 75.25 best_reward: 757.4999880343676\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3560000 / 10000000\n",
      "average reward: 233.91499661058188 average time: 90.25 best_reward: 446.9999933093786\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3570000 / 10000000\n",
      "average reward: 311.98999503292146 average time: 123.65 best_reward: 982.4999882727861\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3580000 / 10000000\n",
      "average reward: 296.994995078817 average time: 145.55 best_reward: 860.2999830245972\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3590000 / 10000000\n",
      "average reward: 176.53499737381935 average time: 60.65 best_reward: 491.59999241679907\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3600000 / 10000000\n",
      "average reward: 237.18999678865075 average time: 90.95 best_reward: 814.5999873951077\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3610000 / 10000000\n",
      "average reward: 236.5349963825196 average time: 93.5 best_reward: 802.499986410141\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3620000 / 10000000\n",
      "average reward: 251.8099960513413 average time: 91.5 best_reward: 814.3999856412411\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3630000 / 10000000\n",
      "average reward: 255.70499856546522 average time: 119.1 best_reward: 1350.1000253483653\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3640000 / 10000000\n",
      "average reward: 269.53999557197096 average time: 93.3 best_reward: 730.0999882146716\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3650000 / 10000000\n",
      "average reward: 289.5249955598265 average time: 127.1 best_reward: 841.399984896183\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3660000 / 10000000\n",
      "average reward: 255.24999649710952 average time: 105.7 best_reward: 542.5999912917614\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3670000 / 10000000\n",
      "average reward: 228.18999691866338 average time: 92.3 best_reward: 610.8999905586243\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3680000 / 10000000\n",
      "average reward: 301.1599955085665 average time: 111.05 best_reward: 812.999990567565\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3690000 / 10000000\n",
      "average reward: 314.4999952740967 average time: 214.85 best_reward: 1115.4999802932143\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3700000 / 10000000\n",
      "average reward: 223.48499676436185 average time: 79.2 best_reward: 626.3999898433685\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3710000 / 10000000\n",
      "average reward: 224.41499663442374 average time: 218.55 best_reward: 641.9999881014228\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3720000 / 10000000\n",
      "average reward: 165.41999773681164 average time: 64.8 best_reward: 369.699994802475\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3730000 / 10000000\n",
      "average reward: 150.83999809287488 average time: 95.1 best_reward: 483.79999189823866\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3740000 / 10000000\n",
      "average reward: 256.01499635577204 average time: 99.55 best_reward: 728.7999902367592\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3750000 / 10000000\n",
      "average reward: 192.23999740295113 average time: 70.1 best_reward: 547.099991619587\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3760000 / 10000000\n",
      "average reward: 198.59499702453613 average time: 69.5 best_reward: 547.2999920248985\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3770000 / 10000000\n",
      "average reward: 869.4299830906093 average time: 141.4 best_reward: 13540.899713911116\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3780000 / 10000000\n",
      "average reward: 258.3199963130057 average time: 97.6 best_reward: 984.199986435473\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3790000 / 10000000\n",
      "average reward: 171.12499778680504 average time: 66.75 best_reward: 404.09999460726976\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3800000 / 10000000\n",
      "average reward: 269.909996239841 average time: 103.5 best_reward: 989.199986346066\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3810000 / 10000000\n",
      "average reward: 289.6399960577488 average time: 164.05 best_reward: 544.99999140203\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3820000 / 10000000\n",
      "average reward: 280.13999641276894 average time: 192.3 best_reward: 894.499985396862\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3830000 / 10000000\n",
      "average reward: 166.33999785371125 average time: 62.25 best_reward: 424.89999475330114\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3840000 / 10000000\n",
      "average reward: 166.56499848775564 average time: 71.75 best_reward: 594.8000030070543\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3850000 / 10000000\n",
      "average reward: 212.76499753408135 average time: 81.95 best_reward: 587.6999917253852\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3860000 / 10000000\n",
      "average reward: 231.65999673493207 average time: 128.25 best_reward: 739.1999904289842\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3870000 / 10000000\n",
      "average reward: 219.24999703355132 average time: 77.5 best_reward: 648.5999895706773\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3880000 / 10000000\n",
      "average reward: 201.12499725297093 average time: 118.5 best_reward: 710.799988143146\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3890000 / 10000000\n",
      "average reward: 225.54499682635068 average time: 122.15 best_reward: 624.2999888062477\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3900000 / 10000000\n",
      "average reward: 412.7399939764291 average time: 154.45 best_reward: 1115.7999801710248\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3910000 / 10000000\n",
      "average reward: 196.04999776259064 average time: 82.1 best_reward: 662.8999898806214\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3920000 / 10000000\n",
      "average reward: 265.5199961990118 average time: 94.15 best_reward: 984.5999879091978\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3930000 / 10000000\n",
      "average reward: 223.71999686695636 average time: 90.4 best_reward: 544.5999921411276\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3940000 / 10000000\n",
      "average reward: 248.3699966236949 average time: 102.85 best_reward: 740.5999903976917\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3950000 / 10000000\n",
      "average reward: 238.4749962788075 average time: 87.25 best_reward: 467.9999917373061\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3960000 / 10000000\n",
      "average reward: 191.0499972190708 average time: 72.4 best_reward: 544.5999891385436\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3970000 / 10000000\n",
      "average reward: 251.91499697864054 average time: 100.65 best_reward: 838.3999883905053\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 3980000 / 10000000\n",
      "average reward: 230.57499691694974 average time: 86.1 best_reward: 711.1999874711037\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 3990000 / 10000000\n",
      "average reward: 268.099996624887 average time: 109.05 best_reward: 986.2999850362539\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4000000 / 10000000\n",
      "average reward: 281.50499715171753 average time: 131.05 best_reward: 871.0000125393271\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4010000 / 10000000\n",
      "average reward: 261.0399961885065 average time: 100.85 best_reward: 1059.099984459579\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4020000 / 10000000\n",
      "average reward: 320.40999535880985 average time: 223.45 best_reward: 980.6999849826097\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4030000 / 10000000\n",
      "average reward: 281.8549962997437 average time: 150.75 best_reward: 725.3999929502606\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4040000 / 10000000\n",
      "average reward: 226.11499677151443 average time: 105.95 best_reward: 649.5999891087413\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4050000 / 10000000\n",
      "average reward: 237.12999655604364 average time: 85.25 best_reward: 407.69999265670776\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4060000 / 10000000\n",
      "average reward: 218.08499809093775 average time: 99.9 best_reward: 764.8000095039606\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4070000 / 10000000\n",
      "average reward: 257.5999965712428 average time: 96.3 best_reward: 610.8999891504645\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4080000 / 10000000\n",
      "average reward: 272.589997285977 average time: 114.15 best_reward: 800.3999862894416\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4090000 / 10000000\n",
      "average reward: 295.51999552473427 average time: 107.85 best_reward: 1114.199984923005\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4100000 / 10000000\n",
      "average reward: 236.69499683976173 average time: 229.4 best_reward: 1115.4999855980277\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4110000 / 10000000\n",
      "average reward: 218.40999721623956 average time: 98.55 best_reward: 591.9999922588468\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4120000 / 10000000\n",
      "average reward: 246.4949964594096 average time: 93.55 best_reward: 835.6999873146415\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4130000 / 10000000\n",
      "average reward: 227.30999655537306 average time: 73.0 best_reward: 621.3999907970428\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4140000 / 10000000\n",
      "average reward: 285.6849958740175 average time: 202.75 best_reward: 656.5999893024564\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4150000 / 10000000\n",
      "average reward: 252.65499604679644 average time: 131.65 best_reward: 1116.6999822705984\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4160000 / 10000000\n",
      "average reward: 297.39499540105464 average time: 117.0 best_reward: 612.1999888792634\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4170000 / 10000000\n",
      "average reward: 213.92999744787812 average time: 178.95 best_reward: 524.5999921858311\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4180000 / 10000000\n",
      "average reward: 207.86999698765575 average time: 73.9 best_reward: 619.8999889642\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4190000 / 10000000\n",
      "average reward: 249.7049964595586 average time: 93.35 best_reward: 771.8999879211187\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4200000 / 10000000\n",
      "average reward: 275.7849962040782 average time: 145.85 best_reward: 718.3999901935458\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4210000 / 10000000\n",
      "average reward: 233.64499666504562 average time: 137.5 best_reward: 436.5999923348427\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4220000 / 10000000\n",
      "average reward: 270.5899963237345 average time: 164.7 best_reward: 978.5999883040786\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4230000 / 10000000\n",
      "average reward: 266.9699966885149 average time: 104.05 best_reward: 799.39999011904\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4240000 / 10000000\n",
      "average reward: 214.24999692961575 average time: 87.7 best_reward: 609.3999898657203\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4250000 / 10000000\n",
      "average reward: 290.8349962126464 average time: 107.2 best_reward: 1064.1999847590923\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4260000 / 10000000\n",
      "average reward: 293.3949960201979 average time: 107.45 best_reward: 815.7999880835414\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4270000 / 10000000\n",
      "average reward: 269.8649960655719 average time: 143.45 best_reward: 830.599986128509\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4280000 / 10000000\n",
      "average reward: 261.88499598763883 average time: 184.35 best_reward: 651.3999900519848\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4290000 / 10000000\n",
      "average reward: 294.80999573729935 average time: 150.85 best_reward: 831.7999898567796\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4300000 / 10000000\n",
      "average reward: 276.09999601989983 average time: 96.6 best_reward: 986.1999877542257\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4310000 / 10000000\n",
      "average reward: 233.1799966584891 average time: 84.45 best_reward: 985.5999880284071\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4320000 / 10000000\n",
      "average reward: 317.8849946960807 average time: 227.55 best_reward: 858.4999847263098\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4330000 / 10000000\n",
      "average reward: 166.28499765582382 average time: 113.1 best_reward: 475.79999116808176\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4340000 / 10000000\n",
      "average reward: 203.77499730810524 average time: 124.1 best_reward: 588.2999914810061\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4350000 / 10000000\n",
      "average reward: 205.1999971881509 average time: 83.0 best_reward: 641.499993249774\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4360000 / 10000000\n",
      "average reward: 282.51999586187304 average time: 137.95 best_reward: 1038.9999846071005\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4370000 / 10000000\n",
      "average reward: 304.7149954549968 average time: 155.75 best_reward: 810.0999905616045\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4380000 / 10000000\n",
      "average reward: 236.12999681085347 average time: 131.65 best_reward: 828.6999904736876\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4390000 / 10000000\n",
      "average reward: 292.1399959187955 average time: 200.9 best_reward: 642.2999909371138\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4400000 / 10000000\n",
      "average reward: 306.03999572619796 average time: 117.7 best_reward: 755.1999886333942\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4410000 / 10000000\n",
      "average reward: 251.57999630868434 average time: 88.05 best_reward: 790.3999893292785\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4420000 / 10000000\n",
      "average reward: 190.86999715454877 average time: 81.1 best_reward: 480.1999932676554\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4430000 / 10000000\n",
      "average reward: 290.51999551169575 average time: 145.85 best_reward: 840.6999846100807\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4440000 / 10000000\n",
      "average reward: 306.7349953867495 average time: 107.9 best_reward: 620.8999887481332\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4450000 / 10000000\n",
      "average reward: 259.3149963863194 average time: 112.55 best_reward: 543.6999920010567\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4460000 / 10000000\n",
      "average reward: 223.11999666206538 average time: 124.15 best_reward: 714.3999876379967\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4470000 / 10000000\n",
      "average reward: 210.19499675184488 average time: 72.15 best_reward: 825.6999865621328\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4480000 / 10000000\n",
      "average reward: 256.1299962379038 average time: 85.05 best_reward: 860.1999866515398\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4490000 / 10000000\n",
      "average reward: 323.3199969805777 average time: 177.55 best_reward: 972.1000127494335\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4500000 / 10000000\n",
      "average reward: 262.954996323213 average time: 91.95 best_reward: 805.299985781312\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4510000 / 10000000\n",
      "average reward: 214.66499692052602 average time: 117.95 best_reward: 801.2999855950475\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4520000 / 10000000\n",
      "average reward: 263.77499634735284 average time: 107.35 best_reward: 1063.4999872595072\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4530000 / 10000000\n",
      "average reward: 325.324995456636 average time: 132.65 best_reward: 1038.9999811425805\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4540000 / 10000000\n",
      "average reward: 286.1499957304448 average time: 101.8 best_reward: 786.999987848103\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4550000 / 10000000\n",
      "average reward: 254.27499635927379 average time: 91.15 best_reward: 595.999992646277\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4560000 / 10000000\n",
      "average reward: 261.73999603390695 average time: 171.6 best_reward: 898.3999834358692\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4570000 / 10000000\n",
      "average reward: 268.3499963976443 average time: 100.75 best_reward: 622.8999897539616\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 4580000 / 10000000\n",
      "average reward: 390.6999944329262 average time: 185.3 best_reward: 1039.9999817758799\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4590000 / 10000000\n",
      "average reward: 233.20499649606646 average time: 80.45 best_reward: 572.9999920651317\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4600000 / 10000000\n",
      "average reward: 251.5499962169677 average time: 131.75 best_reward: 833.5999876782298\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4610000 / 10000000\n",
      "average reward: 268.15999602265657 average time: 97.9 best_reward: 1040.2999818250537\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4620000 / 10000000\n",
      "average reward: 262.9799963068217 average time: 88.05 best_reward: 767.3999897763133\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 4630000 / 10000000\n",
      "average reward: 426.05499390885234 average time: 202.05 best_reward: 1039.1999829113483\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4640000 / 10000000\n",
      "average reward: 291.28999579027294 average time: 109.6 best_reward: 787.499987848103\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4650000 / 10000000\n",
      "average reward: 310.93999548479917 average time: 152.9 best_reward: 1116.2999801710248\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4660000 / 10000000\n",
      "average reward: 292.26999553330245 average time: 148.85 best_reward: 1116.3999791815877\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4670000 / 10000000\n",
      "average reward: 264.6149962183088 average time: 131.8 best_reward: 714.8999901264906\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4680000 / 10000000\n",
      "average reward: 206.5449970714748 average time: 71.55 best_reward: 585.2999916747212\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4690000 / 10000000\n",
      "average reward: 298.8849953755736 average time: 122.2 best_reward: 799.7999868914485\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4700000 / 10000000\n",
      "average reward: 180.7049974411726 average time: 57.55 best_reward: 624.0999903082848\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 4710000 / 10000000\n",
      "average reward: 314.8299955163151 average time: 164.15 best_reward: 981.5999882891774\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4720000 / 10000000\n",
      "average reward: 315.8549949925393 average time: 115.25 best_reward: 835.4999841302633\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4730000 / 10000000\n",
      "average reward: 253.979996689409 average time: 96.05 best_reward: 809.9999921694398\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 4740000 / 10000000\n",
      "average reward: 385.8049947552383 average time: 184.0 best_reward: 1116.2999855652452\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 4750000 / 10000000\n",
      "average reward: 307.8199960093945 average time: 129.5 best_reward: 1039.0999846979976\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4760000 / 10000000\n",
      "average reward: 292.1999963898212 average time: 152.5 best_reward: 1039.199985973537\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4770000 / 10000000\n",
      "average reward: 233.81999678462745 average time: 90.5 best_reward: 542.9999918416142\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4780000 / 10000000\n",
      "average reward: 255.18499646782874 average time: 153.35 best_reward: 549.8999921828508\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4790000 / 10000000\n",
      "average reward: 310.62999527938666 average time: 115.65 best_reward: 1115.9999824613333\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4800000 / 10000000\n",
      "average reward: 272.91499610766766 average time: 96.8 best_reward: 1116.5999825969338\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4810000 / 10000000\n",
      "average reward: 208.67999696247279 average time: 116.35 best_reward: 800.8999886065722\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4820000 / 10000000\n",
      "average reward: 310.63499568887056 average time: 117.4 best_reward: 800.0999868437648\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4830000 / 10000000\n",
      "average reward: 288.8949960887432 average time: 104.0 best_reward: 814.6999902278185\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4840000 / 10000000\n",
      "average reward: 303.0849963907152 average time: 158.3 best_reward: 1117.0999800413847\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4850000 / 10000000\n",
      "average reward: 332.43999614790084 average time: 193.55 best_reward: 809.4999909177423\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4860000 / 10000000\n",
      "average reward: 294.11499567218124 average time: 108.2 best_reward: 800.4999869018793\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4870000 / 10000000\n",
      "average reward: 276.0799960423261 average time: 96.4 best_reward: 1039.7999868020415\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4880000 / 10000000\n",
      "average reward: 268.3849962323904 average time: 96.0 best_reward: 690.9999899491668\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4890000 / 10000000\n",
      "average reward: 284.099997106567 average time: 118.6 best_reward: 871.7000130489469\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4900000 / 10000000\n",
      "average reward: 239.13999896012245 average time: 115.65 best_reward: 1388.9000279083848\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4910000 / 10000000\n",
      "average reward: 287.5099955849349 average time: 96.0 best_reward: 1067.1999826282263\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4920000 / 10000000\n",
      "average reward: 204.63499716706573 average time: 107.45 best_reward: 635.9999913275242\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4930000 / 10000000\n",
      "average reward: 286.47999652400614 average time: 151.4 best_reward: 1116.1999841406941\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4940000 / 10000000\n",
      "average reward: 291.2999963659793 average time: 120.45 best_reward: 1037.7999854013324\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4950000 / 10000000\n",
      "average reward: 240.2099964298308 average time: 179.2 best_reward: 588.299990221858\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4960000 / 10000000\n",
      "average reward: 347.57499605491756 average time: 131.7 best_reward: 1116.5999813005328\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 4970000 / 10000000\n",
      "average reward: 303.6599959407002 average time: 120.0 best_reward: 566.2000029608607\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4980000 / 10000000\n",
      "average reward: 370.514993982017 average time: 160.65 best_reward: 1116.8999797999859\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 4990000 / 10000000\n",
      "average reward: 377.2699943564832 average time: 169.15 best_reward: 985.899988822639\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5000000 / 10000000\n",
      "average reward: 297.13499547876415 average time: 100.05 best_reward: 859.0999844372272\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5010000 / 10000000\n",
      "average reward: 291.03999553024767 average time: 104.2 best_reward: 711.3999863266945\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5020000 / 10000000\n",
      "average reward: 307.594995322451 average time: 155.0 best_reward: 1115.799981854856\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5030000 / 10000000\n",
      "average reward: 405.33999389484524 average time: 194.45 best_reward: 1115.1999839320779\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5040000 / 10000000\n",
      "average reward: 367.3349971175194 average time: 153.15 best_reward: 1373.6000273376703\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5050000 / 10000000\n",
      "average reward: 262.654996278137 average time: 93.35 best_reward: 858.0999863371253\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5060000 / 10000000\n",
      "average reward: 233.5499967381358 average time: 85.5 best_reward: 712.9999888539314\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5070000 / 10000000\n",
      "average reward: 238.2899971295148 average time: 96.3 best_reward: 575.0999924764037\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5080000 / 10000000\n",
      "average reward: 304.0249959867448 average time: 124.9 best_reward: 1070.9999831318855\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5090000 / 10000000\n",
      "average reward: 211.31499662287533 average time: 69.7 best_reward: 590.9999890252948\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5100000 / 10000000\n",
      "average reward: 274.92999581769106 average time: 146.85 best_reward: 973.6999864503741\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5110000 / 10000000\n",
      "average reward: 206.39999726191164 average time: 87.75 best_reward: 493.79999256134033\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5120000 / 10000000\n",
      "average reward: 343.39499520361426 average time: 172.1 best_reward: 1128.0999815165997\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5130000 / 10000000\n",
      "average reward: 331.134995187819 average time: 141.35 best_reward: 1031.699985049665\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5140000 / 10000000\n",
      "average reward: 313.1199950657785 average time: 114.0 best_reward: 858.1999862492085\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5150000 / 10000000\n",
      "average reward: 269.29999591708184 average time: 134.75 best_reward: 1147.099982894957\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5160000 / 10000000\n",
      "average reward: 311.5049953069538 average time: 122.05 best_reward: 774.7999869585037\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5170000 / 10000000\n",
      "average reward: 357.76499440483747 average time: 123.5 best_reward: 805.4999855831265\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5180000 / 10000000\n",
      "average reward: 348.9549948446453 average time: 220.55 best_reward: 811.7999895140529\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5190000 / 10000000\n",
      "average reward: 304.83999520689247 average time: 163.65 best_reward: 728.1999899372458\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5200000 / 10000000\n",
      "average reward: 240.89999630525708 average time: 85.45 best_reward: 618.1999886780977\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5210000 / 10000000\n",
      "average reward: 306.6549951970577 average time: 126.35 best_reward: 623.999989926815\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5220000 / 10000000\n",
      "average reward: 280.879995597899 average time: 162.95 best_reward: 1033.4999815374613\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5230000 / 10000000\n",
      "average reward: 345.80999454557895 average time: 159.5 best_reward: 1116.4999791160226\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5240000 / 10000000\n",
      "average reward: 323.15999486595393 average time: 122.8 best_reward: 990.7999834939837\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5250000 / 10000000\n",
      "average reward: 379.2649963080883 average time: 232.8 best_reward: 1314.4000263363123\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5260000 / 10000000\n",
      "average reward: 461.1799959976226 average time: 213.4 best_reward: 1303.8000243753195\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5270000 / 10000000\n",
      "average reward: 348.71999679729345 average time: 197.15 best_reward: 1355.3000260740519\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5280000 / 10000000\n",
      "average reward: 275.08999877944586 average time: 195.05 best_reward: 1404.2000303938985\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5290000 / 10000000\n",
      "average reward: 326.854995347932 average time: 130.75 best_reward: 985.199989721179\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5300000 / 10000000\n",
      "average reward: 247.8099965363741 average time: 102.3 best_reward: 805.4999860599637\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5310000 / 10000000\n",
      "average reward: 280.86999816708266 average time: 129.75 best_reward: 1322.1000239625573\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5320000 / 10000000\n",
      "average reward: 237.76499662064015 average time: 107.2 best_reward: 839.5999857783318\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5330000 / 10000000\n",
      "average reward: 287.8949978880584 average time: 149.4 best_reward: 1282.6000236198306\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5340000 / 10000000\n",
      "average reward: 350.3349995590746 average time: 218.75 best_reward: 1358.0000263527036\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5350000 / 10000000\n",
      "average reward: 417.85999639332294 average time: 196.5 best_reward: 1361.7000264525414\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5360000 / 10000000\n",
      "average reward: 321.5549956947565 average time: 136.8 best_reward: 1116.6999804377556\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5370000 / 10000000\n",
      "average reward: 348.934994353354 average time: 122.5 best_reward: 1116.8999798297882\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5380000 / 10000000\n",
      "average reward: 368.9699985276908 average time: 235.95 best_reward: 1307.1000237092376\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5390000 / 10000000\n",
      "average reward: 506.2899951037019 average time: 246.15 best_reward: 1220.600021213293\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5400000 / 10000000\n",
      "average reward: 304.08499492257835 average time: 111.25 best_reward: 713.3999871611595\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5410000 / 10000000\n",
      "average reward: 259.22999586202207 average time: 96.8 best_reward: 1077.999980777502\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5420000 / 10000000\n",
      "average reward: 379.67999678365885 average time: 217.85 best_reward: 1404.9000279456377\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5430000 / 10000000\n",
      "average reward: 363.2049991354346 average time: 193.75 best_reward: 1385.300028078258\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5440000 / 10000000\n",
      "average reward: 354.2999978363514 average time: 223.0 best_reward: 1382.2000279650092\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5450000 / 10000000\n",
      "average reward: 219.58999719545244 average time: 87.85 best_reward: 628.4999925792217\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5460000 / 10000000\n",
      "average reward: 240.01499677337705 average time: 101.5 best_reward: 625.1999901533127\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5470000 / 10000000\n",
      "average reward: 443.05499768294396 average time: 221.2 best_reward: 1344.9000276625156\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5480000 / 10000000\n",
      "average reward: 320.97999771386384 average time: 138.1 best_reward: 1399.0000286102295\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5490000 / 10000000\n",
      "average reward: 224.0849968545139 average time: 95.35 best_reward: 627.5999897643924\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5500000 / 10000000\n",
      "average reward: 192.26999739669264 average time: 123.45 best_reward: 499.89999574422836\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5510000 / 10000000\n",
      "average reward: 285.6499957989901 average time: 129.65 best_reward: 983.7999868020415\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5520000 / 10000000\n",
      "average reward: 288.694995797798 average time: 121.0 best_reward: 768.4999871999025\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5530000 / 10000000\n",
      "average reward: 264.88999814577403 average time: 128.0 best_reward: 1203.30002104491\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5540000 / 10000000\n",
      "average reward: 307.1999999552965 average time: 157.1 best_reward: 1367.0000265836716\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5550000 / 10000000\n",
      "average reward: 242.63999858945607 average time: 112.5 best_reward: 1308.5000248849392\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5560000 / 10000000\n",
      "average reward: 224.73499669507146 average time: 87.65 best_reward: 513.5999926254153\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5570000 / 10000000\n",
      "average reward: 387.38999342210593 average time: 171.9 best_reward: 1116.5999794080853\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5580000 / 10000000\n",
      "average reward: 235.5249967828393 average time: 89.55 best_reward: 531.4999931305647\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5590000 / 10000000\n",
      "average reward: 306.1599978066981 average time: 136.7 best_reward: 1372.3000271171331\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5600000 / 10000000\n",
      "average reward: 358.5849971760064 average time: 214.1 best_reward: 1366.100026242435\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5610000 / 10000000\n",
      "average reward: 455.7249981891364 average time: 217.1 best_reward: 1375.5000273287296\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5620000 / 10000000\n",
      "average reward: 329.76999565176664 average time: 174.35 best_reward: 1038.2999857738614\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5630000 / 10000000\n",
      "average reward: 287.3399958569556 average time: 113.05 best_reward: 731.0999913811684\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5640000 / 10000000\n",
      "average reward: 277.4099958088249 average time: 102.2 best_reward: 989.9999849796295\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5650000 / 10000000\n",
      "average reward: 335.034995405376 average time: 199.15 best_reward: 980.0999896526337\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5660000 / 10000000\n",
      "average reward: 314.8199975501746 average time: 135.75 best_reward: 1393.400026872754\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5670000 / 10000000\n",
      "average reward: 475.3099975928664 average time: 227.45 best_reward: 1403.8000282719731\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5680000 / 10000000\n",
      "average reward: 254.91999609023333 average time: 134.45 best_reward: 449.49999338388443\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5690000 / 10000000\n",
      "average reward: 302.58999764844776 average time: 174.65 best_reward: 1395.3000272363424\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5700000 / 10000000\n",
      "average reward: 298.25999783575537 average time: 129.35 best_reward: 1368.2000265941024\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5710000 / 10000000\n",
      "average reward: 292.93499590083957 average time: 156.75 best_reward: 985.2999889031053\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5720000 / 10000000\n",
      "average reward: 380.6749987255782 average time: 188.1 best_reward: 1347.9000254124403\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5730000 / 10000000\n",
      "average reward: 385.1749979417771 average time: 208.45 best_reward: 1344.1000244766474\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5740000 / 10000000\n",
      "average reward: 280.61499564051627 average time: 107.3 best_reward: 1127.5999791547656\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5750000 / 10000000\n",
      "average reward: 221.70499635823072 average time: 81.2 best_reward: 421.39999182522297\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5760000 / 10000000\n",
      "average reward: 289.7399952877313 average time: 145.4 best_reward: 1115.8999804630876\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5770000 / 10000000\n",
      "average reward: 367.2649990607053 average time: 181.25 best_reward: 1372.100026153028\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5780000 / 10000000\n",
      "average reward: 325.9649949617684 average time: 110.7 best_reward: 800.0999858528376\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5790000 / 10000000\n",
      "average reward: 464.9199993152171 average time: 246.85 best_reward: 1329.0000249296427\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5800000 / 10000000\n",
      "average reward: 218.94999713525175 average time: 146.35 best_reward: 612.9999901652336\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5810000 / 10000000\n",
      "average reward: 301.8449981920421 average time: 171.0 best_reward: 1403.2000304982066\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5820000 / 10000000\n",
      "average reward: 276.41499824747444 average time: 153.5 best_reward: 1382.5000284388661\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5830000 / 10000000\n",
      "average reward: 346.50499660260976 average time: 147.95 best_reward: 1199.1000192835927\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5840000 / 10000000\n",
      "average reward: 428.139995791018 average time: 191.1 best_reward: 1304.7000234127045\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 5850000 / 10000000\n",
      "average reward: 355.98499665185807 average time: 156.85 best_reward: 1310.8000242635608\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5860000 / 10000000\n",
      "average reward: 322.50999489985406 average time: 167.05 best_reward: 1141.299980521202\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5870000 / 10000000\n",
      "average reward: 243.21499930955468 average time: 147.7 best_reward: 1391.2000275477767\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5880000 / 10000000\n",
      "average reward: 377.74999715946615 average time: 209.95 best_reward: 1192.7000222578645\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5890000 / 10000000\n",
      "average reward: 331.00999709032476 average time: 152.85 best_reward: 1289.5000223219395\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5900000 / 10000000\n",
      "average reward: 321.8349974170327 average time: 137.15 best_reward: 1311.7000240013003\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5910000 / 10000000\n",
      "average reward: 338.5599973987788 average time: 156.85 best_reward: 1407.1000287607312\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5920000 / 10000000\n",
      "average reward: 500.159997183457 average time: 228.65 best_reward: 1407.5000284612179\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5930000 / 10000000\n",
      "average reward: 231.55999691039324 average time: 157.7 best_reward: 599.8999912440777\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5940000 / 10000000\n",
      "average reward: 386.659998614341 average time: 252.35 best_reward: 1275.9000237807631\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5950000 / 10000000\n",
      "average reward: 246.22999656051397 average time: 150.55 best_reward: 643.8999908640981\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5960000 / 10000000\n",
      "average reward: 291.5699963908643 average time: 128.45 best_reward: 667.9000045582652\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5970000 / 10000000\n",
      "average reward: 332.41499751135706 average time: 145.55 best_reward: 1419.1000290513039\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 5980000 / 10000000\n",
      "average reward: 393.3950015511364 average time: 225.05 best_reward: 1408.8000286072493\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 5990000 / 10000000\n",
      "average reward: 283.6099953290075 average time: 141.3 best_reward: 1116.599980480969\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6000000 / 10000000\n",
      "average reward: 414.97999871224164 average time: 209.4 best_reward: 1412.700029015541\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6010000 / 10000000\n",
      "average reward: 235.07999621927738 average time: 84.4 best_reward: 774.1999858021736\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6020000 / 10000000\n",
      "average reward: 226.09999930895864 average time: 110.55 best_reward: 1404.3000291064382\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6030000 / 10000000\n",
      "average reward: 357.1549966286868 average time: 152.1 best_reward: 1317.1000246331096\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6040000 / 10000000\n",
      "average reward: 320.7099979814142 average time: 144.75 best_reward: 1413.0000291392207\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6050000 / 10000000\n",
      "average reward: 327.0799973167479 average time: 139.95 best_reward: 1410.800028823316\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6060000 / 10000000\n",
      "average reward: 234.7899985883385 average time: 150.9 best_reward: 1340.80002502352\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6070000 / 10000000\n",
      "average reward: 234.3649963285774 average time: 101.05 best_reward: 727.8999896645546\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6080000 / 10000000\n",
      "average reward: 424.6199958942831 average time: 184.0 best_reward: 1396.3000274822116\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6090000 / 10000000\n",
      "average reward: 227.96999667026103 average time: 135.0 best_reward: 743.7999886199832\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6100000 / 10000000\n",
      "average reward: 167.04499757178127 average time: 59.3 best_reward: 595.6999907568097\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6110000 / 10000000\n",
      "average reward: 269.4899983383715 average time: 129.65 best_reward: 1407.2000280171633\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6120000 / 10000000\n",
      "average reward: 339.4249969378114 average time: 154.4 best_reward: 1259.9000232368708\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6130000 / 10000000\n",
      "average reward: 347.0649975415319 average time: 205.95 best_reward: 1373.90002617985\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6140000 / 10000000\n",
      "average reward: 262.7349961798638 average time: 104.35 best_reward: 759.4999880194664\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6150000 / 10000000\n",
      "average reward: 243.27999645918607 average time: 88.35 best_reward: 1115.1999830678105\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6160000 / 10000000\n",
      "average reward: 333.0599973551929 average time: 197.75 best_reward: 1383.7000280693173\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6170000 / 10000000\n",
      "average reward: 333.61499775759876 average time: 178.4 best_reward: 1391.1000281050801\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6180000 / 10000000\n",
      "average reward: 281.9849958900362 average time: 128.55 best_reward: 1029.8999846354127\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6190000 / 10000000\n",
      "average reward: 393.63499637357893 average time: 187.35 best_reward: 1334.5000251680613\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6200000 / 10000000\n",
      "average reward: 236.36999649964272 average time: 95.05 best_reward: 867.0999857783318\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6210000 / 10000000\n",
      "average reward: 278.96999867521225 average time: 177.8 best_reward: 1311.7000235244632\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6220000 / 10000000\n",
      "average reward: 368.9799984503537 average time: 190.15 best_reward: 1324.8000233843923\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6230000 / 10000000\n",
      "average reward: 445.25499576926234 average time: 209.55 best_reward: 1364.2000265195966\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6240000 / 10000000\n",
      "average reward: 258.6049959328026 average time: 87.3 best_reward: 1093.0999802649021\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6250000 / 10000000\n",
      "average reward: 299.579995252192 average time: 155.1 best_reward: 1039.299982137978\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6260000 / 10000000\n",
      "average reward: 335.4199975591153 average time: 160.05 best_reward: 1359.300026446581\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6270000 / 10000000\n",
      "average reward: 316.66499605700375 average time: 114.8 best_reward: 1148.5999779552221\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6280000 / 10000000\n",
      "average reward: 345.8599944513291 average time: 111.25 best_reward: 1039.5999819412827\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6290000 / 10000000\n",
      "average reward: 385.24499394856394 average time: 130.55 best_reward: 1127.0999808087945\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6300000 / 10000000\n",
      "average reward: 266.5099985372275 average time: 131.5 best_reward: 1400.100028090179\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6310000 / 10000000\n",
      "average reward: 292.89499555677173 average time: 97.85 best_reward: 774.7999875694513\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6320000 / 10000000\n",
      "average reward: 319.26999493837354 average time: 128.05 best_reward: 800.3999860659242\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6330000 / 10000000\n",
      "average reward: 379.5099964145571 average time: 187.15 best_reward: 1305.7000222057104\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6340000 / 10000000\n",
      "average reward: 365.25999468937516 average time: 141.65 best_reward: 999.0999819412827\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6350000 / 10000000\n",
      "average reward: 383.3099992237985 average time: 190.35 best_reward: 1372.000026576221\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6360000 / 10000000\n",
      "average reward: 302.7199953511357 average time: 109.4 best_reward: 985.6999851092696\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6370000 / 10000000\n",
      "average reward: 277.8999958522618 average time: 91.3 best_reward: 719.0999898836017\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6380000 / 10000000\n",
      "average reward: 492.6699979096651 average time: 243.95 best_reward: 1402.9000275731087\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6390000 / 10000000\n",
      "average reward: 222.29499717727305 average time: 96.6 best_reward: 492.69999447464943\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6400000 / 10000000\n",
      "average reward: 288.68999812938273 average time: 140.35 best_reward: 1341.5000254139304\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6410000 / 10000000\n",
      "average reward: 313.114997889474 average time: 158.05 best_reward: 1419.4000286608934\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6420000 / 10000000\n",
      "average reward: 292.18499805890025 average time: 215.4 best_reward: 1417.1000294610858\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6430000 / 10000000\n",
      "average reward: 229.2949965622276 average time: 87.7 best_reward: 424.8999935016036\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6440000 / 10000000\n",
      "average reward: 324.8299976568669 average time: 270.1 best_reward: 1346.4000263214111\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6450000 / 10000000\n",
      "average reward: 222.07499692104756 average time: 133.4 best_reward: 403.7999954819679\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6460000 / 10000000\n",
      "average reward: 218.2649968802929 average time: 139.55 best_reward: 416.79999282211065\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6470000 / 10000000\n",
      "average reward: 221.08999699689448 average time: 98.0 best_reward: 480.59999272972345\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6480000 / 10000000\n",
      "average reward: 304.4649957414716 average time: 109.75 best_reward: 1115.1999823749065\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6490000 / 10000000\n",
      "average reward: 262.3049965828657 average time: 107.7 best_reward: 985.4999871328473\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6500000 / 10000000\n",
      "average reward: 358.6299946606159 average time: 133.55 best_reward: 1116.5999806448817\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6510000 / 10000000\n",
      "average reward: 285.2499956957996 average time: 101.45 best_reward: 1071.8999806120992\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6520000 / 10000000\n",
      "average reward: 326.37999538592993 average time: 235.95 best_reward: 1115.399984255433\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6530000 / 10000000\n",
      "average reward: 254.05999679267407 average time: 201.55 best_reward: 752.2999881505966\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6540000 / 10000000\n",
      "average reward: 237.30499652028084 average time: 95.15 best_reward: 801.0999869480729\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6550000 / 10000000\n",
      "average reward: 351.8499996419996 average time: 183.15 best_reward: 1390.500025421381\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6560000 / 10000000\n",
      "average reward: 348.66999445073304 average time: 176.15 best_reward: 1116.599981278181\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6570000 / 10000000\n",
      "average reward: 327.56499669514596 average time: 195.6 best_reward: 1116.9999824687839\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6580000 / 10000000\n",
      "average reward: 448.84499337300656 average time: 157.5 best_reward: 1116.499980904162\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6590000 / 10000000\n",
      "average reward: 292.40499556809664 average time: 137.8 best_reward: 1051.4999810159206\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6600000 / 10000000\n",
      "average reward: 264.4999971866608 average time: 104.9 best_reward: 987.6000084578991\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6610000 / 10000000\n",
      "average reward: 322.3349971950054 average time: 144.7 best_reward: 888.7000036165118\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6620000 / 10000000\n",
      "average reward: 307.85499820075927 average time: 147.5 best_reward: 1396.5000277906656\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6630000 / 10000000\n",
      "average reward: 265.6699974872172 average time: 204.2 best_reward: 1088.7000112980604\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6640000 / 10000000\n",
      "average reward: 179.05999815911053 average time: 92.4 best_reward: 596.0000032037497\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6650000 / 10000000\n",
      "average reward: 250.68499677963555 average time: 116.6 best_reward: 526.3999924883246\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6660000 / 10000000\n",
      "average reward: 307.0399966739118 average time: 126.9 best_reward: 737.8999907299876\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6670000 / 10000000\n",
      "average reward: 261.50499780103564 average time: 108.75 best_reward: 988.4000084996223\n",
      "GOAL\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "GOAL\n",
      "time steps: 6680000 / 10000000\n",
      "average reward: 291.9549969200045 average time: 129.55 best_reward: 1114.4999825432897\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6690000 / 10000000\n",
      "average reward: 302.3949987202883 average time: 149.45 best_reward: 1416.6000283956528\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6700000 / 10000000\n",
      "average reward: 270.4599961601198 average time: 100.7 best_reward: 984.6999871432781\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6710000 / 10000000\n",
      "average reward: 302.2699957206845 average time: 128.05 best_reward: 1112.199983842671\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6720000 / 10000000\n",
      "average reward: 293.47999818250537 average time: 184.85 best_reward: 1362.5000263005495\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6730000 / 10000000\n",
      "average reward: 351.8549981415272 average time: 181.0 best_reward: 1331.9000251367688\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6740000 / 10000000\n",
      "average reward: 352.5949947975576 average time: 163.05 best_reward: 985.4999857023358\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6750000 / 10000000\n",
      "average reward: 274.00499824620783 average time: 124.35 best_reward: 1396.6000275313854\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6760000 / 10000000\n",
      "average reward: 290.769997279346 average time: 136.85 best_reward: 1101.6000181883574\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "GOAL\n",
      "time steps: 6770000 / 10000000\n",
      "average reward: 340.6299965757877 average time: 188.1 best_reward: 1189.6000155434012\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6780000 / 10000000\n",
      "average reward: 301.7299978367984 average time: 136.4 best_reward: 1381.3000278621912\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6790000 / 10000000\n",
      "average reward: 309.98999770507214 average time: 136.35 best_reward: 1382.3000274971128\n",
      "GOAL\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6800000 / 10000000\n",
      "average reward: 283.9949980366975 average time: 122.5 best_reward: 1409.9000291004777\n",
      "<class 'PPO.PPO'>\n",
      "time steps: 6810000 / 10000000\n",
      "average reward: 312.93499507829546 average time: 113.15 best_reward: 894.299982726574\n"
     ]
    }
   ],
   "source": [
    "train('./FinalModelVC', activation_function = torch.nn.Tanh, orthagonal_init=True, grad_norm = 0.5, value_clip = 0.2, value_clip = 0.2, annealing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8674d-e2a9-4b84-bfe4-086e7fcac0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
